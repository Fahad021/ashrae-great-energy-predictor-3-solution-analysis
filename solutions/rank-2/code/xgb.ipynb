{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, GroupKFold, StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, plot_tree\n",
    "\n",
    "DATA_PATH = \"../input/ashrae-energy-prediction/\"\n",
    "LEAKDATA_PATH = \"../input/leakdata/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"train.pkl\", compression = 'zip')\n",
    "test = pd.read_pickle(\"test.pkl\", compression = 'zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "remove_features = ['year','timestamp','meter_reading', \"precip_depth_1_hr\", \"sea_level_pressure\", \"wind_direction\", \"wind_speed\"]\n",
    "features = []\n",
    "for col in train.columns:\n",
    "    if col not in remove_features:\n",
    "        features.append(col)\n",
    "#for col in ['building_id', 'site_id','meter','primary_use','square_feet','year_built','floor_count']:\n",
    "#    try:features.remove(col)\n",
    "#    except:None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categorical_feats = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0]\tvalidation_0-rmse:4.0671\n",
      "Will train until validation_0-rmse hasn't improved in 150 rounds.\n",
      "Stopping. Best iteration:\n",
      "[276]\tvalidation_0-rmse:0.364718\n",
      "\n",
      "[0]\tvalidation_0-rmse:3.98486\n",
      "Will train until validation_0-rmse hasn't improved in 150 rounds.\n",
      "Stopping. Best iteration:\n",
      "[146]\tvalidation_0-rmse:0.453245\n",
      "\n",
      "[0]\tvalidation_0-rmse:3.95473\n",
      "Will train until validation_0-rmse hasn't improved in 150 rounds.\n",
      "Stopping. Best iteration:\n",
      "[374]\tvalidation_0-rmse:0.643221\n",
      "\n",
      "[0]\tvalidation_0-rmse:3.7729\n",
      "Will train until validation_0-rmse hasn't improved in 150 rounds.\n",
      "Stopping. Best iteration:\n",
      "[181]\tvalidation_0-rmse:1.51138\n",
      "\n",
      "[0]\tvalidation_0-rmse:2.58977\n",
      "Will train until validation_0-rmse hasn't improved in 150 rounds.\n",
      "Stopping. Best iteration:\n",
      "[62]\tvalidation_0-rmse:1.61103\n",
      "\n",
      "[0]\tvalidation_0-rmse:2.91297\n",
      "Will train until validation_0-rmse hasn't improved in 150 rounds.\n",
      "Stopping. Best iteration:\n",
      "[37]\tvalidation_0-rmse:1.78827\n",
      "\n",
      "2\n",
      "[0]\tvalidation_0-rmse:3.81435\n",
      "Will train until validation_0-rmse hasn't improved in 150 rounds.\n",
      "Stopping. Best iteration:\n",
      "[172]\tvalidation_0-rmse:0.365988\n",
      "\n",
      "[0]\tvalidation_0-rmse:3.81476\n",
      "Will train until validation_0-rmse hasn't improved in 150 rounds.\n",
      "Stopping. Best iteration:\n",
      "[352]\tvalidation_0-rmse:0.30152\n",
      "\n",
      "[0]\tvalidation_0-rmse:3.80282\n",
      "Will train until validation_0-rmse hasn't improved in 150 rounds.\n",
      "Stopping. Best iteration:\n",
      "[432]\tvalidation_0-rmse:0.316408\n",
      "\n",
      "[0]\tvalidation_0-rmse:3.96333\n",
      "Will train until validation_0-rmse hasn't improved in 150 rounds.\n",
      "Stopping. Best iteration:\n",
      "[113]\tvalidation_0-rmse:1.19173\n",
      "\n",
      "[0]\tvalidation_0-rmse:4.70808\n",
      "Will train until validation_0-rmse hasn't improved in 150 rounds.\n",
      "Stopping. Best iteration:\n",
      "[168]\tvalidation_0-rmse:1.13779\n",
      "\n",
      "[0]\tvalidation_0-rmse:4.14078\n",
      "Will train until validation_0-rmse hasn't improved in 150 rounds.\n",
      "Stopping. Best iteration:\n",
      "[290]\tvalidation_0-rmse:1.15658\n",
      "\n",
      "[0]\tvalidation_0-rmse:2.8155\n",
      "Will train until validation_0-rmse hasn't improved in 150 rounds.\n",
      "Stopping. Best iteration:\n",
      "[207]\tvalidation_0-rmse:1.23759\n",
      "\n",
      "[0]\tvalidation_0-rmse:2.12248\n",
      "Will train until validation_0-rmse hasn't improved in 150 rounds.\n",
      "Stopping. Best iteration:\n",
      "[69]\tvalidation_0-rmse:0.751087\n",
      "\n",
      "[0]\tvalidation_0-rmse:2.43941\n",
      "Will train until validation_0-rmse hasn't improved in 150 rounds.\n",
      "Stopping. Best iteration:\n",
      "[70]\tvalidation_0-rmse:1.07066\n",
      "\n",
      "3\n",
      "[0]\tvalidation_0-rmse:3.40424\n",
      "Will train until validation_0-rmse hasn't improved in 150 rounds.\n",
      "Stopping. Best iteration:\n",
      "[138]\tvalidation_0-rmse:0.426506\n",
      "\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-82ec7e48b6d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvl_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvl_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0moof\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_small\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mpredictions\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_small\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mtest_small\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'meter_reading'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnum_folds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mtest_small\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'meter_reading'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_small\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'meter_reading'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_small\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"meter_reading\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_small\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"meter_reading\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[0;32m    446\u001b[0m         \"\"\"\n\u001b[0;32m    447\u001b[0m         \u001b[1;31m# pylint: disable=missing-docstring,invalid-name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m         \u001b[0mtest_dmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m         \u001b[1;31m# get ntree_limit to use - if none specified, default to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m         \u001b[1;31m# best_ntree_limit if defined, otherwise 0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_npy2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataTable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_dt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_init_from_npy2d\u001b[1;34m(self, mat, missing, nthread)\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;31m# we try to avoid data copies if possible (reshape returns a view when possible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m         \u001b[1;31m# and we explicitly tell np.array to try and avoid copying)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 478\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    479\u001b[0m         \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_folds = 3\n",
    "#folds = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "folds = KFold(n_splits = num_folds, shuffle = False, random_state = 42)\n",
    "#train.dropna(subset=['meter_reading'], inplace=True)\n",
    "t = []\n",
    "tr_oof = []\n",
    "a = 0\n",
    "for site_id in train['site_id'].unique():\n",
    "    a += 1\n",
    "    print(a)\n",
    "    for meter in train[train['site_id'] == site_id]['meter'].unique():\n",
    "        train_small = train[(train['site_id'] == site_id) & (train['meter'] == meter)]\n",
    "        test_small = test[(test['site_id'] == site_id) & (test['meter'] == meter)]\n",
    "        oof = np.zeros(len(train_small))\n",
    "        predictions = np.zeros(len(test_small))\n",
    "        target = np.log1p(train_small[\"meter_reading\"])\n",
    "        for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_small, train_small['month'])):\n",
    "            tr_x, tr_y = train_small.iloc[trn_idx][features], target.iloc[trn_idx]\n",
    "            vl_x, vl_y = train_small.iloc[val_idx][features], target.iloc[val_idx]\n",
    "\n",
    "            clf = xgb.XGBRegressor(\n",
    "                      n_estimators=6000,\n",
    "                      max_depth=12,\n",
    "                      num_boost_round=500,\n",
    "                      learning_rate=0.05,\n",
    "                      subsample=0.8,\n",
    "                      colsample_bytree=0.4,\n",
    "                      missing=np.nan,\n",
    "                      objective ='reg:squarederror',\n",
    "                      tree_method='hist'\n",
    "                      )\n",
    "            h = clf.fit(tr_x, tr_y,eval_set=[(vl_x, vl_y)],early_stopping_rounds=150,verbose=2000)\n",
    "            oof[val_idx] = clf.predict(train_small.iloc[val_idx][features])\n",
    "            predictions += np.expm1(clf.predict(test_small[features]))\n",
    "        test_small['meter_reading'] = predictions / num_folds\n",
    "        test_small['meter_reading'] = test_small['meter_reading'].clip(train_small[\"meter_reading\"].min(),train_small[\"meter_reading\"].max())\n",
    "        train_small['meter_reading_p'] = oof\n",
    "        t.append(test_small[['meter_reading']])\n",
    "        tr_oof.append(train_small[['meter_reading_p']])\n",
    "t = pd.concat(t)\n",
    "t = t.sort_index()\n",
    "oof = pd.concat(tr_oof)\n",
    "oof = oof.sort_index()\n",
    "#print(np.sqrt(mean_squared_error(target, oof['meter_reading_p'])))\n",
    "try:del test['meter_reading']\n",
    "except:None\n",
    "test = test.merge(t, left_index=True, right_index=True, how='left')\n",
    "target = np.log1p(train[\"meter_reading\"])\n",
    "print(np.sqrt(mean_squared_error(target, oof['meter_reading_p'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_folds = 4\n",
    "#folds = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "folds = KFold(n_splits = num_folds, shuffle = False, random_state = 42)\n",
    "#train.dropna(subset=['meter_reading'], inplace=True)\n",
    "t = []\n",
    "tr_oof = []\n",
    "a = 0\n",
    "for building_id in train['building_id'].unique():\n",
    "    a += 1\n",
    "    print(a)\n",
    "    for meter in train[train['building_id'] == building_id]['meter'].unique():\n",
    "        train_small = train[(train['building_id'] == building_id) & (train['meter'] == meter)]\n",
    "        test_small = test[(test['building_id'] == building_id) & (test['meter'] == meter)]\n",
    "        oof = np.zeros(len(train_small))\n",
    "        predictions = np.zeros(len(test_small))\n",
    "        target = np.log1p(train_small[\"meter_reading\"])\n",
    "        for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_small, train_small['month'])):\n",
    "            tr_x, tr_y = train_small.iloc[trn_idx][features], target.iloc[trn_idx]\n",
    "            vl_x, vl_y = train_small.iloc[val_idx][features], target.iloc[val_idx]\n",
    "\n",
    "            clf = xgb.XGBRegressor(\n",
    "                      n_estimators=6000,\n",
    "                      max_depth=12,\n",
    "                      num_boost_round=500,\n",
    "                      learning_rate=0.1,\n",
    "                      subsample=0.8,\n",
    "                      colsample_bytree=0.4,\n",
    "                      missing=np.nan,\n",
    "                      objective ='reg:squarederror',\n",
    "                      tree_method='hist'\n",
    "                      )\n",
    "            h = clf.fit(tr_x, tr_y,eval_set=[(vl_x, vl_y)],early_stopping_rounds=50,verbose=2000)\n",
    "            oof[val_idx] = clf.predict(train_small.iloc[val_idx][features])\n",
    "            predictions += np.expm1(clf.predict(test_small[features]))\n",
    "        test_small['meter_reading_building_id'] = predictions / num_folds\n",
    "        test_small['meter_reading_building_id'] = test_small['meter_reading_building_id'].clip(train_small[\"meter_reading\"].min(),train_small[\"meter_reading\"].max())\n",
    "        train_small['meter_reading_p'] = oof\n",
    "        t.append(test_small[['meter_reading_building_id']])\n",
    "        tr_oof.append(train_small[['meter_reading_p']])\n",
    "t = pd.concat(t)\n",
    "t = t.sort_index()\n",
    "oof = pd.concat(tr_oof)\n",
    "oof = oof.sort_index()\n",
    "#print(np.sqrt(mean_squared_error(target, oof['meter_reading_p'])))\n",
    "try:del test['meter_reading_building_id']\n",
    "except:None\n",
    "test = test.merge(t, left_index=True, right_index=True, how='left')\n",
    "target = np.log1p(train[\"meter_reading\"])\n",
    "print(np.sqrt(mean_squared_error(target, oof['meter_reading_p'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_folds = 4\n",
    "#folds = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "folds = KFold(n_splits = num_folds, shuffle = False, random_state = 42)\n",
    "#train.dropna(subset=['meter_reading'], inplace=True)\n",
    "t = []\n",
    "tr_oof = []\n",
    "a = 0\n",
    "for primary_use in train['primary_use'].unique():\n",
    "    a += 1\n",
    "    print(a, primary_use)\n",
    "    for meter in train[train['primary_use'] == primary_use]['meter'].unique():\n",
    "        train_small = train[(train['primary_use'] == primary_use) & (train['meter'] == meter)]\n",
    "        test_small = test[(test['primary_use'] == primary_use) & (test['meter'] == meter)]\n",
    "        oof = np.zeros(len(train_small))\n",
    "        predictions = np.zeros(len(test_small))\n",
    "        target = np.log1p(train_small[\"meter_reading\"])\n",
    "        for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_small, train_small['month'])):\n",
    "            tr_x, tr_y = train_small.iloc[trn_idx][features], target.iloc[trn_idx]\n",
    "            vl_x, vl_y = train_small.iloc[val_idx][features], target.iloc[val_idx]\n",
    "\n",
    "            clf = xgb.XGBRegressor(\n",
    "                      n_estimators=6000,\n",
    "                      max_depth=12,\n",
    "                      num_boost_round=500,\n",
    "                      learning_rate=0.05,\n",
    "                      subsample=0.8,\n",
    "                      colsample_bytree=0.4,\n",
    "                      missing=np.nan,\n",
    "                      objective ='reg:squarederror',\n",
    "                      tree_method='hist'\n",
    "                      )\n",
    "            #h = clf.fit(tr_x, tr_y,eval_set=[(vl_x, vl_y)],early_stopping_rounds=150,verbose=2000)\n",
    "            clf.fit(tr_x, tr_y,eval_set=[(vl_x, vl_y)],early_stopping_rounds=150,verbose=2000)\n",
    "            oof[val_idx] = clf.predict(train_small.iloc[val_idx][features])\n",
    "            predictions += np.expm1(clf.predict(test_small[features]))\n",
    "        test_small['meter_reading_primary_use'] = predictions / num_folds\n",
    "        test_small['meter_reading_primary_use'] = test_small['meter_reading_primary_use'].clip(train_small[\"meter_reading\"].min(),train_small[\"meter_reading\"].max())\n",
    "        train_small['meter_reading_p'] = oof\n",
    "        t.append(test_small[['meter_reading_primary_use']])\n",
    "        tr_oof.append(train_small[['meter_reading_p']])\n",
    "t = pd.concat(t)\n",
    "t = t.sort_index()\n",
    "oof = pd.concat(tr_oof)\n",
    "oof = oof.sort_index()\n",
    "#print(np.sqrt(mean_squared_error(target, oof['meter_reading_p'])))\n",
    "try:del test['meter_reading_primary_use']\n",
    "except:None\n",
    "test = test.merge(t, left_index=True, right_index=True, how='left')\n",
    "target = np.log1p(train[\"meter_reading\"])\n",
    "print(np.sqrt(mean_squared_error(target, oof['meter_reading_p'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"sample_submission.csv\")\n",
    "sub[\"meter_reading\"] = test['meter_reading'] * 0.6 + test['meter_reading_primary_use'] * 0.2 + test['meter_reading_building_id'] * 0.2\n",
    "#sub.to_csv(\"best_xgb.gz\",  index = False, compression= 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test = test.rename(columns={'meter_reading':'meter_reading_site_id'})\n",
    "#test[\"meter_reading\"] = test['meter_reading_site_id'] #* 0.6 + test['meter_reading_primary_use'] * 0.2 + test['meter_reading_building_id'] * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['meter_reading'] = sub[\"meter_reading\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test['meter_reading'] = [meter_r * 0.85 if site not in [0,1,2,3,4,15] else meter_r for meter_r,site in zip(test['meter_reading'], test['site_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "leak_df = pd.read_csv(LEAKDATA_PATH+'leak.csv')\n",
    "leak_df['timestamp'] = pd.to_datetime(leak_df[\"timestamp\"])\n",
    "leak_df.dropna(0, inplace=True)\n",
    "leak_df = leak_df[(leak_df.timestamp.dt.year > 2016) & (leak_df.timestamp.dt.year < 2019)]\n",
    "leak_df.loc[leak_df.meter_reading < 0, 'meter_reading'] = 0 # remove large negative values\n",
    "leak_df = leak_df[leak_df.building_id!=245]\n",
    "leak_df['meter_reading_sc'] = leak_df['meter_reading'] \n",
    "del leak_df['meter_reading'] \n",
    "test = test.merge(leak_df, on=['building_id','meter','timestamp'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test['meter_reading'] = [a if (a >= 0 and site != 4) or (a < 0 and site != 4) else b for a,b,site in zip(test['meter_reading_sc'], test['meter_reading'], test['site_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub[\"meter_reading\"] = test['meter_reading']\n",
    "sub.to_csv(\"../sub/xgb_3wise.csv\",  index = False,float_format=\"%.4f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
