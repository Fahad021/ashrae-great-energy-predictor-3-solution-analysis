{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on https://www.kaggle.com/isaienkov/keras-nn-with-embeddings-for-cat-features-1-15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(this is a keras tensorflow so no need to change /.keras/keras.json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T12:58:02.737896Z",
     "start_time": "2020-04-23T12:58:01.064890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (0.17.0)\r\n",
      "Requirement already satisfied: numpy>=1.14 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pyarrow) (1.16.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T12:58:04.803499Z",
     "start_time": "2020-04-23T12:58:02.740346Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./weather_test.csv\n",
      "./requirement.txt\n",
      "./level1--submission_multimeter004_nobuild--lightgbm.ipynb\n",
      "./ashrae-energy-prediction.zip\n",
      "./generate_leak_data.ipynb\n",
      "./level1--submission_withoutleak001--lightgbm.ipynb\n",
      "./train_simple_cleanup.feather\n",
      "./train.csv\n",
      "./train_cleanup_001.feather\n",
      "./README.md\n",
      "./model_summary.pdf\n",
      "./cpumemuse_densenn.txt\n",
      "./weather_train.csv\n",
      "./level1--submission_whatsyourcv3_0052_trncl--lightgbm.ipynb\n",
      "./level1--submission_multimeter003--lightgbm.ipynb\n",
      "./cpumemuse.sh\n",
      "./generate_datasets.ipynb\n",
      "./level1--submission_nn001--DenseNN.ipynb\n",
      "./test.csv\n",
      "./model_0.hdf5\n",
      "./level1--submission_nn007lofo--CNN.ipynb\n",
      "./level2--ensembling_model.ipynb\n",
      "./building_metadata.csv\n",
      "./memuse_log.sh\n",
      "./sample_submission.csv\n",
      "./.ipynb_checkpoints/level1--submission_nn001--DenseNN-checkpoint.ipynb\n",
      "./Catboost on GPU/requirement.txt\n",
      "./Catboost on GPU/level1--catboost002--Catboost.ipynb\n",
      "./Keras_NN_weights/cnn_model_0.hdf5\n",
      "./Keras_NN_weights/cnn_model_1.hdf5\n",
      "./Keras_NN_weights/model_1.hdf5\n",
      "./Keras_NN_weights/model_0.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('./'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dropout, Dense, Embedding, SpatialDropout1D, concatenate, BatchNormalization, Flatten\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.losses import mean_squared_error as mse_loss\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T12:58:04.809618Z",
     "start_time": "2020-04-23T12:58:04.805839Z"
    }
   },
   "outputs": [],
   "source": [
    "def average_imputation(df, column_name):\n",
    "    imputation = df.groupby(['timestamp'])[column_name].mean()\n",
    "    \n",
    "    df.loc[df[column_name].isnull(), column_name] = df[df[column_name].isnull()][[column_name]].apply(lambda x: imputation[df['timestamp'][x.index]].values)\n",
    "    del imputation\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T12:58:13.814823Z",
     "start_time": "2020-04-23T12:58:04.811679Z"
    },
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "building_df = pd.read_csv(\"./building_metadata.csv\")\n",
    "weather_train = pd.read_csv(\"./weather_train.csv\")\n",
    "train = pd.read_feather(\"./train_cleanup_001.feather\")\n",
    "\n",
    "train = train.merge(building_df, left_on = \"building_id\", right_on = \"building_id\", how = \"left\")\n",
    "train = train.merge(weather_train, left_on = [\"site_id\", \"timestamp\"], right_on = [\"site_id\", \"timestamp\"])\n",
    "del weather_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T12:58:24.364219Z",
     "start_time": "2020-04-23T12:58:13.817063Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train.loc[(train['meter']==0) & (train['site_id']==0) & (train['timestamp']<'2016-05-21 00:00:00'), 'drop'] = True\n",
    "train = train[train['drop']!=True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T12:58:33.337769Z",
     "start_time": "2020-04-23T12:58:24.367037Z"
    }
   },
   "outputs": [],
   "source": [
    "train[\"timestamp\"] = pd.to_datetime(train[\"timestamp\"])\n",
    "train[\"hour\"] = train[\"timestamp\"].dt.hour\n",
    "train[\"weekday\"] = train[\"timestamp\"].dt.weekday\n",
    "\n",
    "train = average_imputation(train, 'wind_speed')\n",
    "\n",
    "beaufort = [(0, 0, 0.3), (1, 0.3, 1.6), (2, 1.6, 3.4), (3, 3.4, 5.5), (4, 5.5, 8), (5, 8, 10.8), (6, 10.8, 13.9), \n",
    "          (7, 13.9, 17.2), (8, 17.2, 20.8), (9, 20.8, 24.5), (10, 24.5, 28.5), (11, 28.5, 33), (12, 33, 200)]\n",
    "\n",
    "for item in beaufort:\n",
    "    train.loc[(train['wind_speed']>=item[1]) & (train['wind_speed']<item[2]), 'beaufort_scale'] = item[0]\n",
    "\n",
    "del train[\"timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T12:58:33.351530Z",
     "start_time": "2020-04-23T12:58:33.340379Z"
    }
   },
   "outputs": [],
   "source": [
    "#Based on this great kernel https://www.kaggle.com/arjanso/reducing-dataframe-memory-size-by-65\n",
    "def reduce_mem_usage(df):\n",
    "    start_mem_usg = df.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
    "    NAlist = [] # Keeps track of columns that have missing values filled in. \n",
    "    for col in df.columns:\n",
    "        if df[col].dtype != object:  # Exclude strings            \n",
    "            # Print current column type\n",
    "            print(\"******************************\")\n",
    "            print(\"Column: \",col)\n",
    "            print(\"dtype before: \",df[col].dtype)            \n",
    "            # make variables for Int, max and min\n",
    "            IsInt = False\n",
    "            mx = df[col].max()\n",
    "            mn = df[col].min()\n",
    "            meancol = df[col].mean()\n",
    "            print(\"min for this col: \",mn)\n",
    "            print(\"max for this col: \",mx)\n",
    "            # Integer does not support NA, therefore, NA needs to be filled\n",
    "            if not np.isfinite(df[col]).all(): \n",
    "                NAlist.append(col)\n",
    "                df[col].fillna(meancol,inplace=True)  \n",
    "                \n",
    "                print('change for', meancol)\n",
    "                   \n",
    "            # test if column can be converted to an integer\n",
    "            asint = df[col].fillna(0).astype(np.int64)\n",
    "            result = (df[col] - asint)\n",
    "            result = result.sum()\n",
    "            if result > -0.01 and result < 0.01:\n",
    "                IsInt = True            \n",
    "            # Make Integer/unsigned Integer datatypes\n",
    "            if IsInt:\n",
    "                if mn >= 0:\n",
    "                    if mx < 255:\n",
    "                        df[col] = df[col].astype(np.uint8)\n",
    "                    elif mx < 65535:\n",
    "                        df[col] = df[col].astype(np.uint16)\n",
    "                    elif mx < 4294967295:\n",
    "                        df[col] = df[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)    \n",
    "            # Make float datatypes 32 bit\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "            \n",
    "            # Print new column type\n",
    "            print(\"dtype after: \",df[col].dtype)\n",
    "            print(\"******************************\")\n",
    "    # Print final result\n",
    "    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
    "    mem_usg = df.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    return df, NAlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T12:58:36.918460Z",
     "start_time": "2020-04-23T12:58:33.353897Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "train[\"primary_use\"] = le.fit_transform(train[\"primary_use\"])\n",
    "\n",
    "categoricals = [\"site_id\", \"building_id\", \"primary_use\", \"hour\", \"weekday\",  \"meter\"]\n",
    "\n",
    "drop_cols = [\"sea_level_pressure\", \"wind_speed\", \"wind_direction\"]\n",
    "\n",
    "numericals = [\"square_feet\", \"year_built\", \"air_temperature\", \"cloud_coverage\",\n",
    "              \"dew_temperature\", \"precip_depth_1_hr\", \"floor_count\", 'beaufort_scale']\n",
    "\n",
    "feat_cols = categoricals + numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T12:58:38.505746Z",
     "start_time": "2020-04-23T12:58:36.920687Z"
    }
   },
   "outputs": [],
   "source": [
    "target = np.log1p(train[\"meter_reading\"])\n",
    "\n",
    "del train[\"meter_reading\"] \n",
    "\n",
    "train = train.drop(drop_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T12:58:47.511099Z",
     "start_time": "2020-04-23T12:58:38.508026Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of properties dataframe is : 3033.1971435546875  MB\n",
      "******************************\n",
      "Column:  building_id\n",
      "dtype before:  int64\n",
      "min for this col:  0\n",
      "max for this col:  1448\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  meter\n",
      "dtype before:  int64\n",
      "min for this col:  0\n",
      "max for this col:  3\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  site_id\n",
      "dtype before:  int64\n",
      "min for this col:  0\n",
      "max for this col:  15\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  primary_use\n",
      "dtype before:  int64\n",
      "min for this col:  0\n",
      "max for this col:  15\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  square_feet\n",
      "dtype before:  int64\n",
      "min for this col:  283\n",
      "max for this col:  875000\n",
      "dtype after:  uint32\n",
      "******************************\n",
      "******************************\n",
      "Column:  year_built\n",
      "dtype before:  float64\n",
      "min for this col:  1900.0\n",
      "max for this col:  2017.0\n",
      "change for 1967.0896632561887\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  floor_count\n",
      "dtype before:  float64\n",
      "min for this col:  1.0\n",
      "max for this col:  26.0\n",
      "change for 4.1275720129163735\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  air_temperature\n",
      "dtype before:  float64\n",
      "min for this col:  -28.9\n",
      "max for this col:  47.2\n",
      "change for 15.892317471254808\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  cloud_coverage\n",
      "dtype before:  float64\n",
      "min for this col:  0.0\n",
      "max for this col:  9.0\n",
      "change for 1.8927767298442322\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  dew_temperature\n",
      "dtype before:  float64\n",
      "min for this col:  -35.0\n",
      "max for this col:  26.1\n",
      "change for 7.618798497952911\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  precip_depth_1_hr\n",
      "dtype before:  float64\n",
      "min for this col:  -1.0\n",
      "max for this col:  343.0\n",
      "change for 0.7906748946516636\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  hour\n",
      "dtype before:  int64\n",
      "min for this col:  0\n",
      "max for this col:  23\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  weekday\n",
      "dtype before:  int64\n",
      "min for this col:  0\n",
      "max for this col:  6\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  beaufort_scale\n",
      "dtype before:  float64\n",
      "min for this col:  0.0\n",
      "max for this col:  8.0\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  1612.2363395690918  MB\n",
      "This is  53.153035007796014 % of the initial size\n"
     ]
    }
   ],
   "source": [
    "train, NAlist = reduce_mem_usage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T12:58:47.530170Z",
     "start_time": "2020-04-23T12:58:47.514057Z"
    }
   },
   "outputs": [],
   "source": [
    "def model(dense_dim_1=64, dense_dim_2=32, dense_dim_3=32, dense_dim_4=16, \n",
    "dropout1=0.2, dropout2=0.1, dropout3=0.1, dropout4=0.1, lr=0.001):\n",
    "\n",
    "    #Inputs\n",
    "    site_id = Input(shape=[1], name=\"site_id\")\n",
    "    building_id = Input(shape=[1], name=\"building_id\")\n",
    "    meter = Input(shape=[1], name=\"meter\")\n",
    "    primary_use = Input(shape=[1], name=\"primary_use\")\n",
    "    square_feet = Input(shape=[1], name=\"square_feet\")\n",
    "    year_built = Input(shape=[1], name=\"year_built\")\n",
    "    air_temperature = Input(shape=[1], name=\"air_temperature\")\n",
    "    cloud_coverage = Input(shape=[1], name=\"cloud_coverage\")\n",
    "    dew_temperature = Input(shape=[1], name=\"dew_temperature\")\n",
    "    hour = Input(shape=[1], name=\"hour\")\n",
    "    precip = Input(shape=[1], name=\"precip_depth_1_hr\")\n",
    "    weekday = Input(shape=[1], name=\"weekday\")\n",
    "    beaufort_scale = Input(shape=[1], name=\"beaufort_scale\")\n",
    "   \n",
    "    #Embeddings layers\n",
    "    emb_site_id = Embedding(16, 2)(site_id)\n",
    "    emb_building_id = Embedding(1449, 6)(building_id)\n",
    "    emb_meter = Embedding(4, 2)(meter)\n",
    "    emb_primary_use = Embedding(16, 2)(primary_use)\n",
    "    emb_hour = Embedding(24, 3)(hour)\n",
    "    emb_weekday = Embedding(7, 2)(weekday)\n",
    "\n",
    "    concat_emb = concatenate([\n",
    "           Flatten() (emb_site_id)\n",
    "         , Flatten() (emb_building_id)\n",
    "         , Flatten() (emb_meter)\n",
    "         , Flatten() (emb_primary_use)\n",
    "         , Flatten() (emb_hour)\n",
    "         , Flatten() (emb_weekday)\n",
    "    ])\n",
    "    \n",
    "    categ = Dropout(dropout1)(Dense(dense_dim_1,activation='relu') (concat_emb))\n",
    "    categ = BatchNormalization()(categ)\n",
    "    categ = Dropout(dropout2)(Dense(dense_dim_2,activation='relu') (categ))\n",
    "    \n",
    "    #main layer\n",
    "    main_l = concatenate([\n",
    "          categ\n",
    "        , square_feet\n",
    "        , year_built\n",
    "        , air_temperature\n",
    "        , cloud_coverage\n",
    "        , dew_temperature\n",
    "        , precip\n",
    "        , beaufort_scale\n",
    "    ])\n",
    "    \n",
    "    main_l = Dropout(dropout3)(Dense(dense_dim_3,activation='relu') (main_l))\n",
    "    main_l = BatchNormalization()(main_l)\n",
    "    \n",
    "    main_2 = concatenate([\n",
    "          main_l\n",
    "        , Flatten() (emb_building_id)\n",
    "        , Flatten() (emb_site_id)\n",
    "\n",
    "    ])\n",
    "    \n",
    "    main_2 = Dropout(dropout4)(Dense(dense_dim_4,activation='relu') (main_2))\n",
    "    \n",
    "    #output\n",
    "    output = Dense(1) (main_2)\n",
    "\n",
    "    model = Model([ site_id,\n",
    "                    building_id, \n",
    "                    meter, \n",
    "                    primary_use, \n",
    "                    square_feet, \n",
    "                    year_built, \n",
    "                   \n",
    "                    air_temperature,\n",
    "                    cloud_coverage,\n",
    "                    dew_temperature, \n",
    "                    hour,\n",
    "                    weekday, \n",
    "                    precip,\n",
    "                    beaufort_scale], output)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr=lr),\n",
    "                  loss= mse_loss,\n",
    "                  metrics=[root_mean_squared_error])\n",
    "    return model\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T12:58:47.537560Z",
     "start_time": "2020-04-23T12:58:47.532213Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_keras_data(df, num_cols, cat_cols):\n",
    "    cols = cat_cols + num_cols\n",
    "    X = {col: np.array(df[col]) for col in cols}\n",
    "    return X\n",
    "\n",
    "def train_model(keras_model, X_t, y_train, batch_size, epochs, X_v, y_valid, fold, patience=3):\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=1)\n",
    "    model_checkpoint = ModelCheckpoint(\"model_\" + str(fold) + \".hdf5\",\n",
    "                                       save_best_only=True, verbose=1, monitor='val_root_mean_squared_error', mode='min')\n",
    "\n",
    "    hist = keras_model.fit(X_t, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                            validation_data=(X_v, y_valid), verbose=1,\n",
    "                            callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "    keras_model = load_model(\"model_\" + str(fold) + \".hdf5\", custom_objects={'root_mean_squared_error': root_mean_squared_error})\n",
    "    \n",
    "    return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T17:56:27.063016Z",
     "start_time": "2020-04-23T12:58:47.539657Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 9802535 samples, validate on 9802536 samples\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:184: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "9802535/9802535 [==============================] - 560s 57us/step - loss: 1.3307 - root_mean_squared_error: 1.1347 - val_loss: 1.3429 - val_root_mean_squared_error: 1.1053\n",
      "\n",
      "Epoch 00001: val_root_mean_squared_error improved from inf to 1.10534, saving model to model_0.hdf5\n",
      "Epoch 2/15\n",
      "9802535/9802535 [==============================] - 560s 57us/step - loss: 0.9660 - root_mean_squared_error: 0.9771 - val_loss: 1.1692 - val_root_mean_squared_error: 1.0305\n",
      "\n",
      "Epoch 00002: val_root_mean_squared_error improved from 1.10534 to 1.03046, saving model to model_0.hdf5\n",
      "Epoch 3/15\n",
      "9802535/9802535 [==============================] - 563s 57us/step - loss: 0.9023 - root_mean_squared_error: 0.9440 - val_loss: 1.1432 - val_root_mean_squared_error: 1.0206\n",
      "\n",
      "Epoch 00003: val_root_mean_squared_error improved from 1.03046 to 1.02061, saving model to model_0.hdf5\n",
      "Epoch 4/15\n",
      "9802535/9802535 [==============================] - 565s 58us/step - loss: 0.8732 - root_mean_squared_error: 0.9285 - val_loss: 1.2889 - val_root_mean_squared_error: 1.0683\n",
      "\n",
      "Epoch 00004: val_root_mean_squared_error did not improve from 1.02061\n",
      "Epoch 5/15\n",
      "9802535/9802535 [==============================] - 566s 58us/step - loss: 0.8574 - root_mean_squared_error: 0.9199 - val_loss: 1.1250 - val_root_mean_squared_error: 1.0127\n",
      "\n",
      "Epoch 00005: val_root_mean_squared_error improved from 1.02061 to 1.01265, saving model to model_0.hdf5\n",
      "Epoch 6/15\n",
      "9802535/9802535 [==============================] - 565s 58us/step - loss: 0.8453 - root_mean_squared_error: 0.9134 - val_loss: 1.1460 - val_root_mean_squared_error: 1.0191\n",
      "\n",
      "Epoch 00006: val_root_mean_squared_error did not improve from 1.01265\n",
      "Epoch 7/15\n",
      "9802535/9802535 [==============================] - 564s 58us/step - loss: 0.8373 - root_mean_squared_error: 0.9090 - val_loss: 1.0982 - val_root_mean_squared_error: 0.9978\n",
      "\n",
      "Epoch 00007: val_root_mean_squared_error improved from 1.01265 to 0.99780, saving model to model_0.hdf5\n",
      "Epoch 8/15\n",
      "9802535/9802535 [==============================] - 565s 58us/step - loss: 0.8284 - root_mean_squared_error: 0.9041 - val_loss: 1.0850 - val_root_mean_squared_error: 0.9927\n",
      "\n",
      "Epoch 00008: val_root_mean_squared_error improved from 0.99780 to 0.99271, saving model to model_0.hdf5\n",
      "Epoch 9/15\n",
      "9802535/9802535 [==============================] - 566s 58us/step - loss: 0.8211 - root_mean_squared_error: 0.9000 - val_loss: 1.0803 - val_root_mean_squared_error: 0.9917\n",
      "\n",
      "Epoch 00009: val_root_mean_squared_error improved from 0.99271 to 0.99168, saving model to model_0.hdf5\n",
      "Epoch 10/15\n",
      "9802535/9802535 [==============================] - 568s 58us/step - loss: 0.8160 - root_mean_squared_error: 0.8972 - val_loss: 1.0992 - val_root_mean_squared_error: 0.9996\n",
      "\n",
      "Epoch 00010: val_root_mean_squared_error did not improve from 0.99168\n",
      "Epoch 11/15\n",
      "9802535/9802535 [==============================] - 569s 58us/step - loss: 0.8123 - root_mean_squared_error: 0.8951 - val_loss: 1.0628 - val_root_mean_squared_error: 0.9833\n",
      "\n",
      "Epoch 00011: val_root_mean_squared_error improved from 0.99168 to 0.98332, saving model to model_0.hdf5\n",
      "Epoch 12/15\n",
      "9802535/9802535 [==============================] - 566s 58us/step - loss: 0.8070 - root_mean_squared_error: 0.8922 - val_loss: 1.0775 - val_root_mean_squared_error: 0.9903\n",
      "\n",
      "Epoch 00012: val_root_mean_squared_error did not improve from 0.98332\n",
      "Epoch 13/15\n",
      "9802535/9802535 [==============================] - 566s 58us/step - loss: 0.8025 - root_mean_squared_error: 0.8896 - val_loss: 1.0675 - val_root_mean_squared_error: 0.9862\n",
      "\n",
      "Epoch 00013: val_root_mean_squared_error did not improve from 0.98332\n",
      "Epoch 14/15\n",
      "9802535/9802535 [==============================] - 567s 58us/step - loss: 0.7988 - root_mean_squared_error: 0.8876 - val_loss: 1.0613 - val_root_mean_squared_error: 0.9814\n",
      "\n",
      "Epoch 00014: val_root_mean_squared_error improved from 0.98332 to 0.98140, saving model to model_0.hdf5\n",
      "Epoch 15/15\n",
      "9802535/9802535 [==============================] - 568s 58us/step - loss: 0.7953 - root_mean_squared_error: 0.8855 - val_loss: 1.0967 - val_root_mean_squared_error: 0.9958\n",
      "\n",
      "Epoch 00015: val_root_mean_squared_error did not improve from 0.98140\n",
      "**************************************************\n",
      "Fold: 1\n",
      "Train on 9802536 samples, validate on 9802535 samples\n",
      "Epoch 1/15\n",
      "9802536/9802536 [==============================] - 620s 63us/step - loss: 1.4275 - root_mean_squared_error: 1.1778 - val_loss: 1.3225 - val_root_mean_squared_error: 1.0989\n",
      "\n",
      "Epoch 00001: val_root_mean_squared_error improved from inf to 1.09895, saving model to model_1.hdf5\n",
      "Epoch 2/15\n",
      "9802536/9802536 [==============================] - 655s 67us/step - loss: 1.0076 - root_mean_squared_error: 0.9983 - val_loss: 1.2486 - val_root_mean_squared_error: 1.0627\n",
      "\n",
      "Epoch 00002: val_root_mean_squared_error improved from 1.09895 to 1.06265, saving model to model_1.hdf5\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9802536/9802536 [==============================] - 620s 63us/step - loss: 0.9018 - root_mean_squared_error: 0.9441 - val_loss: 1.1185 - val_root_mean_squared_error: 1.0117\n",
      "\n",
      "Epoch 00003: val_root_mean_squared_error improved from 1.06265 to 1.01167, saving model to model_1.hdf5\n",
      "Epoch 4/15\n",
      "9802536/9802536 [==============================] - 617s 63us/step - loss: 0.8577 - root_mean_squared_error: 0.9206 - val_loss: 1.1584 - val_root_mean_squared_error: 1.0260\n",
      "\n",
      "Epoch 00004: val_root_mean_squared_error did not improve from 1.01167\n",
      "Epoch 5/15\n",
      "9802536/9802536 [==============================] - 620s 63us/step - loss: 0.8338 - root_mean_squared_error: 0.9075 - val_loss: 1.1020 - val_root_mean_squared_error: 1.0025\n",
      "\n",
      "Epoch 00005: val_root_mean_squared_error improved from 1.01167 to 1.00249, saving model to model_1.hdf5\n",
      "Epoch 6/15\n",
      "9802536/9802536 [==============================] - 618s 63us/step - loss: 0.8197 - root_mean_squared_error: 0.8997 - val_loss: 1.1094 - val_root_mean_squared_error: 1.0035\n",
      "\n",
      "Epoch 00006: val_root_mean_squared_error did not improve from 1.00249\n",
      "Epoch 7/15\n",
      "9802536/9802536 [==============================] - 620s 63us/step - loss: 0.8103 - root_mean_squared_error: 0.8946 - val_loss: 1.0576 - val_root_mean_squared_error: 0.9805\n",
      "\n",
      "Epoch 00007: val_root_mean_squared_error improved from 1.00249 to 0.98049, saving model to model_1.hdf5\n",
      "Epoch 8/15\n",
      "9802536/9802536 [==============================] - 620s 63us/step - loss: 0.8042 - root_mean_squared_error: 0.8912 - val_loss: 1.0893 - val_root_mean_squared_error: 0.9949\n",
      "\n",
      "Epoch 00008: val_root_mean_squared_error did not improve from 0.98049\n",
      "Epoch 9/15\n",
      "9802536/9802536 [==============================] - 620s 63us/step - loss: 0.7991 - root_mean_squared_error: 0.8882 - val_loss: 1.0654 - val_root_mean_squared_error: 0.9837\n",
      "\n",
      "Epoch 00009: val_root_mean_squared_error did not improve from 0.98049\n",
      "Epoch 10/15\n",
      "9802536/9802536 [==============================] - 623s 64us/step - loss: 0.7935 - root_mean_squared_error: 0.8851 - val_loss: 1.0560 - val_root_mean_squared_error: 0.9802\n",
      "\n",
      "Epoch 00010: val_root_mean_squared_error improved from 0.98049 to 0.98018, saving model to model_1.hdf5\n",
      "Epoch 11/15\n",
      "9802536/9802536 [==============================] - 619s 63us/step - loss: 0.7889 - root_mean_squared_error: 0.8826 - val_loss: 1.0613 - val_root_mean_squared_error: 0.9821\n",
      "\n",
      "Epoch 00011: val_root_mean_squared_error did not improve from 0.98018\n",
      "Epoch 12/15\n",
      "9802536/9802536 [==============================] - 621s 63us/step - loss: 0.7841 - root_mean_squared_error: 0.8798 - val_loss: 1.0439 - val_root_mean_squared_error: 0.9745\n",
      "\n",
      "Epoch 00012: val_root_mean_squared_error improved from 0.98018 to 0.97454, saving model to model_1.hdf5\n",
      "Epoch 13/15\n",
      "9802536/9802536 [==============================] - 620s 63us/step - loss: 0.7809 - root_mean_squared_error: 0.8780 - val_loss: 1.0560 - val_root_mean_squared_error: 0.9806\n",
      "\n",
      "Epoch 00013: val_root_mean_squared_error did not improve from 0.97454\n",
      "Epoch 14/15\n",
      "9802536/9802536 [==============================] - 623s 64us/step - loss: 0.7777 - root_mean_squared_error: 0.8762 - val_loss: 1.0408 - val_root_mean_squared_error: 0.9737\n",
      "\n",
      "Epoch 00014: val_root_mean_squared_error improved from 0.97454 to 0.97371, saving model to model_1.hdf5\n",
      "Epoch 15/15\n",
      "9802536/9802536 [==============================] - 621s 63us/step - loss: 0.7756 - root_mean_squared_error: 0.8749 - val_loss: 1.0512 - val_root_mean_squared_error: 0.9775\n",
      "\n",
      "Epoch 00015: val_root_mean_squared_error did not improve from 0.97371\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "oof = np.zeros(len(train))\n",
    "batch_size = 256\n",
    "epochs = 15\n",
    "models = []\n",
    "\n",
    "folds = 2\n",
    "seed = 666\n",
    "\n",
    "kf = StratifiedKFold(n_splits=folds, shuffle=False, random_state=seed)\n",
    "\n",
    "for fold_n, (train_index, valid_index) in enumerate(kf.split(train, train['building_id'])):\n",
    "    print('Fold:', fold_n)\n",
    "    X_train, X_valid = train.iloc[train_index], train.iloc[valid_index]\n",
    "    y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "    X_t = get_keras_data(X_train, numericals, categoricals)\n",
    "    X_v = get_keras_data(X_valid, numericals, categoricals)\n",
    "    \n",
    "    keras_model = model(dense_dim_1=64, dense_dim_2=32, dense_dim_3=32, dense_dim_4=16, \n",
    "                        dropout1=0.2, dropout2=0.1, dropout3=0.1, dropout4=0.1, lr=0.001)\n",
    "    mod = train_model(keras_model, X_t, y_train, batch_size, epochs, X_v, y_valid, fold_n, patience=3)\n",
    "    models.append(mod)\n",
    "    print('*'* 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T21:23:36.674217Z",
     "start_time": "2020-04-23T18:08:06.605704Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Train on 9802535 samples, validate on 9802536 samples\n",
      "Epoch 1/15\n",
      "9802535/9802535 [==============================] - 628s 64us/step - loss: 1.4041 - root_mean_squared_error: 1.1641 - val_loss: 1.2889 - val_root_mean_squared_error: 1.0835\n",
      "\n",
      "Epoch 00001: val_root_mean_squared_error improved from inf to 1.08355, saving model to model_0.hdf5\n",
      "Epoch 2/15\n",
      "9802535/9802535 [==============================] - 621s 63us/step - loss: 0.9752 - root_mean_squared_error: 0.9816 - val_loss: 1.1493 - val_root_mean_squared_error: 1.0194\n",
      "\n",
      "Epoch 00002: val_root_mean_squared_error improved from 1.08355 to 1.01940, saving model to model_0.hdf5\n",
      "Epoch 3/15\n",
      "9802535/9802535 [==============================] - 624s 64us/step - loss: 0.8981 - root_mean_squared_error: 0.9419 - val_loss: 1.1769 - val_root_mean_squared_error: 1.0392\n",
      "\n",
      "Epoch 00003: val_root_mean_squared_error did not improve from 1.01940\n",
      "Epoch 4/15\n",
      "9802535/9802535 [==============================] - 623s 64us/step - loss: 0.8614 - root_mean_squared_error: 0.9221 - val_loss: 1.0797 - val_root_mean_squared_error: 0.9924\n",
      "\n",
      "Epoch 00004: val_root_mean_squared_error improved from 1.01940 to 0.99240, saving model to model_0.hdf5\n",
      "Epoch 5/15\n",
      "9802535/9802535 [==============================] - 625s 64us/step - loss: 0.8395 - root_mean_squared_error: 0.9102 - val_loss: 1.0866 - val_root_mean_squared_error: 0.9936\n",
      "\n",
      "Epoch 00005: val_root_mean_squared_error did not improve from 0.99240\n",
      "Epoch 6/15\n",
      "9802535/9802535 [==============================] - 628s 64us/step - loss: 0.8262 - root_mean_squared_error: 0.9029 - val_loss: 1.0823 - val_root_mean_squared_error: 0.9895\n",
      "\n",
      "Epoch 00006: val_root_mean_squared_error improved from 0.99240 to 0.98952, saving model to model_0.hdf5\n",
      "Epoch 7/15\n",
      "9802535/9802535 [==============================] - 629s 64us/step - loss: 0.8186 - root_mean_squared_error: 0.8987 - val_loss: 1.0592 - val_root_mean_squared_error: 0.9797\n",
      "\n",
      "Epoch 00007: val_root_mean_squared_error improved from 0.98952 to 0.97974, saving model to model_0.hdf5\n",
      "Epoch 8/15\n",
      "9802535/9802535 [==============================] - 629s 64us/step - loss: 0.8116 - root_mean_squared_error: 0.8947 - val_loss: 1.0627 - val_root_mean_squared_error: 0.9822\n",
      "\n",
      "Epoch 00008: val_root_mean_squared_error did not improve from 0.97974\n",
      "Epoch 9/15\n",
      "9802535/9802535 [==============================] - 628s 64us/step - loss: 0.8068 - root_mean_squared_error: 0.8920 - val_loss: 1.0900 - val_root_mean_squared_error: 0.9952\n",
      "\n",
      "Epoch 00009: val_root_mean_squared_error did not improve from 0.97974\n",
      "Epoch 10/15\n",
      "9802535/9802535 [==============================] - 627s 64us/step - loss: 0.8018 - root_mean_squared_error: 0.8892 - val_loss: 1.0967 - val_root_mean_squared_error: 0.9944\n",
      "\n",
      "Epoch 00010: val_root_mean_squared_error did not improve from 0.97974\n",
      "Epoch 00010: early stopping\n",
      "**************************************************\n",
      "Fold: 1\n",
      "Train on 9802536 samples, validate on 9802535 samples\n",
      "Epoch 1/15\n",
      "9802536/9802536 [==============================] - 668s 68us/step - loss: 1.2772 - root_mean_squared_error: 1.1117 - val_loss: 1.4331 - val_root_mean_squared_error: 1.1386\n",
      "\n",
      "Epoch 00001: val_root_mean_squared_error improved from inf to 1.13863, saving model to model_1.hdf5\n",
      "Epoch 2/15\n",
      "9802536/9802536 [==============================] - 658s 67us/step - loss: 0.9802 - root_mean_squared_error: 0.9847 - val_loss: 1.2674 - val_root_mean_squared_error: 1.0714\n",
      "\n",
      "Epoch 00002: val_root_mean_squared_error improved from 1.13863 to 1.07141, saving model to model_1.hdf5\n",
      "Epoch 3/15\n",
      "9802536/9802536 [==============================] - 665s 68us/step - loss: 0.9006 - root_mean_squared_error: 0.9434 - val_loss: 1.1140 - val_root_mean_squared_error: 1.0087\n",
      "\n",
      "Epoch 00003: val_root_mean_squared_error improved from 1.07141 to 1.00867, saving model to model_1.hdf5\n",
      "Epoch 4/15\n",
      "9802536/9802536 [==============================] - 715s 73us/step - loss: 0.8584 - root_mean_squared_error: 0.9210 - val_loss: 1.1177 - val_root_mean_squared_error: 1.0105\n",
      "\n",
      "Epoch 00004: val_root_mean_squared_error did not improve from 1.00867\n",
      "Epoch 5/15\n",
      "9802536/9802536 [==============================] - 665s 68us/step - loss: 0.8393 - root_mean_squared_error: 0.9105 - val_loss: 1.0672 - val_root_mean_squared_error: 0.9868\n",
      "\n",
      "Epoch 00005: val_root_mean_squared_error improved from 1.00867 to 0.98678, saving model to model_1.hdf5\n",
      "Epoch 6/15\n",
      "9802536/9802536 [==============================] - 665s 68us/step - loss: 0.8244 - root_mean_squared_error: 0.9024 - val_loss: 1.1276 - val_root_mean_squared_error: 1.0145\n",
      "\n",
      "Epoch 00006: val_root_mean_squared_error did not improve from 0.98678\n",
      "Epoch 7/15\n",
      "9802536/9802536 [==============================] - 706s 72us/step - loss: 0.8107 - root_mean_squared_error: 0.8947 - val_loss: 1.1626 - val_root_mean_squared_error: 1.0267\n",
      "\n",
      "Epoch 00007: val_root_mean_squared_error did not improve from 0.98678\n",
      "Epoch 8/15\n",
      "9802536/9802536 [==============================] - 666s 68us/step - loss: 0.8004 - root_mean_squared_error: 0.8889 - val_loss: 1.0948 - val_root_mean_squared_error: 1.0001\n",
      "\n",
      "Epoch 00008: val_root_mean_squared_error did not improve from 0.98678\n",
      "Epoch 00008: early stopping\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "oof = np.zeros(len(train))\n",
    "batch_size = 256\n",
    "epochs = 15\n",
    "models = []\n",
    "\n",
    "folds = 2\n",
    "seed = 666\n",
    "\n",
    "kf = StratifiedKFold(n_splits=folds, shuffle=False, random_state=seed)\n",
    "\n",
    "for fold_n, (train_index, valid_index) in enumerate(kf.split(train, train['building_id'])):\n",
    "    print('Fold:', fold_n)\n",
    "    X_train, X_valid = train.iloc[train_index], train.iloc[valid_index]\n",
    "    y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "    X_t = get_keras_data(X_train, numericals, categoricals)\n",
    "    X_v = get_keras_data(X_valid, numericals, categoricals)\n",
    "    \n",
    "    keras_model = model(dense_dim_1=64, dense_dim_2=32, dense_dim_3=32, dense_dim_4=16, \n",
    "                        dropout1=0.2, dropout2=0.1, dropout3=0.1, dropout4=0.1, lr=0.001)\n",
    "    mod = train_model(keras_model, X_t, y_train, batch_size, epochs, X_v, y_valid, fold_n, patience=3)\n",
    "    models.append(mod)\n",
    "    print('*'* 50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T21:23:36.687626Z",
     "start_time": "2020-04-23T21:23:36.676801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['square_feet',\n",
       " 'year_built',\n",
       " 'air_temperature',\n",
       " 'cloud_coverage',\n",
       " 'dew_temperature',\n",
       " 'precip_depth_1_hr',\n",
       " 'floor_count',\n",
       " 'beaufort_scale']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T21:23:37.266822Z",
     "start_time": "2020-04-23T21:23:36.689725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del train, target, X_train, X_valid, y_train, y_valid, X_t, X_v, kf\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T21:24:18.742601Z",
     "start_time": "2020-04-23T21:23:37.269109Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./test.csv\")\n",
    "test = test.merge(building_df, left_on = \"building_id\", right_on = \"building_id\", how = \"left\")\n",
    "del building_df\n",
    "gc.collect()\n",
    "test[\"primary_use\"] = le.transform(test[\"primary_use\"])\n",
    "\n",
    "weather_test = pd.read_csv(\"./weather_test.csv\")\n",
    "\n",
    "test = test.merge(weather_test, left_on = [\"site_id\", \"timestamp\"], right_on = [\"site_id\", \"timestamp\"], how = \"left\")\n",
    "del weather_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T21:24:57.607681Z",
     "start_time": "2020-04-23T21:24:18.745435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of properties dataframe is : 6051.91162109375  MB\n",
      "******************************\n",
      "Column:  site_id\n",
      "dtype before:  int64\n",
      "min for this col:  0\n",
      "max for this col:  15\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  building_id\n",
      "dtype before:  int64\n",
      "min for this col:  0\n",
      "max for this col:  1448\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  primary_use\n",
      "dtype before:  int64\n",
      "min for this col:  0\n",
      "max for this col:  15\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  hour\n",
      "dtype before:  int64\n",
      "min for this col:  0\n",
      "max for this col:  23\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  weekday\n",
      "dtype before:  int64\n",
      "min for this col:  0\n",
      "max for this col:  6\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  meter\n",
      "dtype before:  int64\n",
      "min for this col:  0\n",
      "max for this col:  3\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  square_feet\n",
      "dtype before:  int64\n",
      "min for this col:  283\n",
      "max for this col:  875000\n",
      "dtype after:  uint32\n",
      "******************************\n",
      "******************************\n",
      "Column:  year_built\n",
      "dtype before:  float64\n",
      "min for this col:  1900.0\n",
      "max for this col:  2017.0\n",
      "change for 1968.170081967213\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  air_temperature\n",
      "dtype before:  float64\n",
      "min for this col:  -28.1\n",
      "max for this col:  48.3\n",
      "change for 15.505707129926357\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  cloud_coverage\n",
      "dtype before:  float64\n",
      "min for this col:  0.0\n",
      "max for this col:  9.0\n",
      "change for 1.9733458449444876\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  dew_temperature\n",
      "dtype before:  float64\n",
      "min for this col:  -31.6\n",
      "max for this col:  26.7\n",
      "change for 7.585971305989484\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  precip_depth_1_hr\n",
      "dtype before:  float64\n",
      "min for this col:  -1.0\n",
      "max for this col:  597.0\n",
      "change for 0.9182989150029545\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  floor_count\n",
      "dtype before:  float64\n",
      "min for this col:  1.0\n",
      "max for this col:  26.0\n",
      "change for 4.120772946859903\n",
      "dtype after:  float32\n",
      "******************************\n",
      "******************************\n",
      "Column:  beaufort_scale\n",
      "dtype before:  float64\n",
      "min for this col:  0.0\n",
      "max for this col:  9.0\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  3029.700927734375  MB\n",
      "This is  50.061883210165306 % of the initial size\n"
     ]
    }
   ],
   "source": [
    "test[\"timestamp\"] = pd.to_datetime(test[\"timestamp\"])\n",
    "test[\"hour\"] = test[\"timestamp\"].dt.hour\n",
    "test[\"weekday\"] = test[\"timestamp\"].dt.weekday\n",
    "\n",
    "test = average_imputation(test, 'wind_speed')\n",
    "\n",
    "for item in beaufort:\n",
    "    test.loc[(test['wind_speed']>=item[1]) & (test['wind_speed']<item[2]), 'beaufort_scale'] = item[0]\n",
    "\n",
    "    \n",
    "test = test[feat_cols]\n",
    "test, NAlist = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T00:22:42.764506Z",
     "start_time": "2020-04-24T00:22:39.179225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm==4.32.2 in /home/ubuntu/.local/lib/python3.6/site-packages (4.32.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm==4.32.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T00:46:08.738457Z",
     "start_time": "2020-04-24T00:35:50.957079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 - count 0\n",
      "iteration 1 - count 50000\n",
      "iteration 2 - count 100000\n",
      "iteration 3 - count 150000\n",
      "iteration 4 - count 200000\n",
      "iteration 5 - count 250000\n",
      "iteration 6 - count 300000\n",
      "iteration 7 - count 350000\n",
      "iteration 8 - count 400000\n",
      "iteration 9 - count 450000\n",
      "iteration 10 - count 500000\n",
      "iteration 11 - count 550000\n",
      "iteration 12 - count 600000\n",
      "iteration 13 - count 650000\n",
      "iteration 14 - count 700000\n",
      "iteration 15 - count 750000\n",
      "iteration 16 - count 800000\n",
      "iteration 17 - count 850000\n",
      "iteration 18 - count 900000\n",
      "iteration 19 - count 950000\n",
      "iteration 20 - count 1000000\n",
      "iteration 21 - count 1050000\n",
      "iteration 22 - count 1100000\n",
      "iteration 23 - count 1150000\n",
      "iteration 24 - count 1200000\n",
      "iteration 25 - count 1250000\n",
      "iteration 26 - count 1300000\n",
      "iteration 27 - count 1350000\n",
      "iteration 28 - count 1400000\n",
      "iteration 29 - count 1450000\n",
      "iteration 30 - count 1500000\n",
      "iteration 31 - count 1550000\n",
      "iteration 32 - count 1600000\n",
      "iteration 33 - count 1650000\n",
      "iteration 34 - count 1700000\n",
      "iteration 35 - count 1750000\n",
      "iteration 36 - count 1800000\n",
      "iteration 37 - count 1850000\n",
      "iteration 38 - count 1900000\n",
      "iteration 39 - count 1950000\n",
      "iteration 40 - count 2000000\n",
      "iteration 41 - count 2050000\n",
      "iteration 42 - count 2100000\n",
      "iteration 43 - count 2150000\n",
      "iteration 44 - count 2200000\n",
      "iteration 45 - count 2250000\n",
      "iteration 46 - count 2300000\n",
      "iteration 47 - count 2350000\n",
      "iteration 48 - count 2400000\n",
      "iteration 49 - count 2450000\n",
      "iteration 50 - count 2500000\n",
      "iteration 51 - count 2550000\n",
      "iteration 52 - count 2600000\n",
      "iteration 53 - count 2650000\n",
      "iteration 54 - count 2700000\n",
      "iteration 55 - count 2750000\n",
      "iteration 56 - count 2800000\n",
      "iteration 57 - count 2850000\n",
      "iteration 58 - count 2900000\n",
      "iteration 59 - count 2950000\n",
      "iteration 60 - count 3000000\n",
      "iteration 61 - count 3050000\n",
      "iteration 62 - count 3100000\n",
      "iteration 63 - count 3150000\n",
      "iteration 64 - count 3200000\n",
      "iteration 65 - count 3250000\n",
      "iteration 66 - count 3300000\n",
      "iteration 67 - count 3350000\n",
      "iteration 68 - count 3400000\n",
      "iteration 69 - count 3450000\n",
      "iteration 70 - count 3500000\n",
      "iteration 71 - count 3550000\n",
      "iteration 72 - count 3600000\n",
      "iteration 73 - count 3650000\n",
      "iteration 74 - count 3700000\n",
      "iteration 75 - count 3750000\n",
      "iteration 76 - count 3800000\n",
      "iteration 77 - count 3850000\n",
      "iteration 78 - count 3900000\n",
      "iteration 79 - count 3950000\n",
      "iteration 80 - count 4000000\n",
      "iteration 81 - count 4050000\n",
      "iteration 82 - count 4100000\n",
      "iteration 83 - count 4150000\n",
      "iteration 84 - count 4200000\n",
      "iteration 85 - count 4250000\n",
      "iteration 86 - count 4300000\n",
      "iteration 87 - count 4350000\n",
      "iteration 88 - count 4400000\n",
      "iteration 89 - count 4450000\n",
      "iteration 90 - count 4500000\n",
      "iteration 91 - count 4550000\n",
      "iteration 92 - count 4600000\n",
      "iteration 93 - count 4650000\n",
      "iteration 94 - count 4700000\n",
      "iteration 95 - count 4750000\n",
      "iteration 96 - count 4800000\n",
      "iteration 97 - count 4850000\n",
      "iteration 98 - count 4900000\n",
      "iteration 99 - count 4950000\n",
      "iteration 100 - count 5000000\n",
      "iteration 101 - count 5050000\n",
      "iteration 102 - count 5100000\n",
      "iteration 103 - count 5150000\n",
      "iteration 104 - count 5200000\n",
      "iteration 105 - count 5250000\n",
      "iteration 106 - count 5300000\n",
      "iteration 107 - count 5350000\n",
      "iteration 108 - count 5400000\n",
      "iteration 109 - count 5450000\n",
      "iteration 110 - count 5500000\n",
      "iteration 111 - count 5550000\n",
      "iteration 112 - count 5600000\n",
      "iteration 113 - count 5650000\n",
      "iteration 114 - count 5700000\n",
      "iteration 115 - count 5750000\n",
      "iteration 116 - count 5800000\n",
      "iteration 117 - count 5850000\n",
      "iteration 118 - count 5900000\n",
      "iteration 119 - count 5950000\n",
      "iteration 120 - count 6000000\n",
      "iteration 121 - count 6050000\n",
      "iteration 122 - count 6100000\n",
      "iteration 123 - count 6150000\n",
      "iteration 124 - count 6200000\n",
      "iteration 125 - count 6250000\n",
      "iteration 126 - count 6300000\n",
      "iteration 127 - count 6350000\n",
      "iteration 128 - count 6400000\n",
      "iteration 129 - count 6450000\n",
      "iteration 130 - count 6500000\n",
      "iteration 131 - count 6550000\n",
      "iteration 132 - count 6600000\n",
      "iteration 133 - count 6650000\n",
      "iteration 134 - count 6700000\n",
      "iteration 135 - count 6750000\n",
      "iteration 136 - count 6800000\n",
      "iteration 137 - count 6850000\n",
      "iteration 138 - count 6900000\n",
      "iteration 139 - count 6950000\n",
      "iteration 140 - count 7000000\n",
      "iteration 141 - count 7050000\n",
      "iteration 142 - count 7100000\n",
      "iteration 143 - count 7150000\n",
      "iteration 144 - count 7200000\n",
      "iteration 145 - count 7250000\n",
      "iteration 146 - count 7300000\n",
      "iteration 147 - count 7350000\n",
      "iteration 148 - count 7400000\n",
      "iteration 149 - count 7450000\n",
      "iteration 150 - count 7500000\n",
      "iteration 151 - count 7550000\n",
      "iteration 152 - count 7600000\n",
      "iteration 153 - count 7650000\n",
      "iteration 154 - count 7700000\n",
      "iteration 155 - count 7750000\n",
      "iteration 156 - count 7800000\n",
      "iteration 157 - count 7850000\n",
      "iteration 158 - count 7900000\n",
      "iteration 159 - count 7950000\n",
      "iteration 160 - count 8000000\n",
      "iteration 161 - count 8050000\n",
      "iteration 162 - count 8100000\n",
      "iteration 163 - count 8150000\n",
      "iteration 164 - count 8200000\n",
      "iteration 165 - count 8250000\n",
      "iteration 166 - count 8300000\n",
      "iteration 167 - count 8350000\n",
      "iteration 168 - count 8400000\n",
      "iteration 169 - count 8450000\n",
      "iteration 170 - count 8500000\n",
      "iteration 171 - count 8550000\n",
      "iteration 172 - count 8600000\n",
      "iteration 173 - count 8650000\n",
      "iteration 174 - count 8700000\n",
      "iteration 175 - count 8750000\n",
      "iteration 176 - count 8800000\n",
      "iteration 177 - count 8850000\n",
      "iteration 178 - count 8900000\n",
      "iteration 179 - count 8950000\n",
      "iteration 180 - count 9000000\n",
      "iteration 181 - count 9050000\n",
      "iteration 182 - count 9100000\n",
      "iteration 183 - count 9150000\n",
      "iteration 184 - count 9200000\n",
      "iteration 185 - count 9250000\n",
      "iteration 186 - count 9300000\n",
      "iteration 187 - count 9350000\n",
      "iteration 188 - count 9400000\n",
      "iteration 189 - count 9450000\n",
      "iteration 190 - count 9500000\n",
      "iteration 191 - count 9550000\n",
      "iteration 192 - count 9600000\n",
      "iteration 193 - count 9650000\n",
      "iteration 194 - count 9700000\n",
      "iteration 195 - count 9750000\n",
      "iteration 196 - count 9800000\n",
      "iteration 197 - count 9850000\n",
      "iteration 198 - count 9900000\n",
      "iteration 199 - count 9950000\n",
      "iteration 200 - count 10000000\n",
      "iteration 201 - count 10050000\n",
      "iteration 202 - count 10100000\n",
      "iteration 203 - count 10150000\n",
      "iteration 204 - count 10200000\n",
      "iteration 205 - count 10250000\n",
      "iteration 206 - count 10300000\n",
      "iteration 207 - count 10350000\n",
      "iteration 208 - count 10400000\n",
      "iteration 209 - count 10450000\n",
      "iteration 210 - count 10500000\n",
      "iteration 211 - count 10550000\n",
      "iteration 212 - count 10600000\n",
      "iteration 213 - count 10650000\n",
      "iteration 214 - count 10700000\n",
      "iteration 215 - count 10750000\n",
      "iteration 216 - count 10800000\n",
      "iteration 217 - count 10850000\n",
      "iteration 218 - count 10900000\n",
      "iteration 219 - count 10950000\n",
      "iteration 220 - count 11000000\n",
      "iteration 221 - count 11050000\n",
      "iteration 222 - count 11100000\n",
      "iteration 223 - count 11150000\n",
      "iteration 224 - count 11200000\n",
      "iteration 225 - count 11250000\n",
      "iteration 226 - count 11300000\n",
      "iteration 227 - count 11350000\n",
      "iteration 228 - count 11400000\n",
      "iteration 229 - count 11450000\n",
      "iteration 230 - count 11500000\n",
      "iteration 231 - count 11550000\n",
      "iteration 232 - count 11600000\n",
      "iteration 233 - count 11650000\n",
      "iteration 234 - count 11700000\n",
      "iteration 235 - count 11750000\n",
      "iteration 236 - count 11800000\n",
      "iteration 237 - count 11850000\n",
      "iteration 238 - count 11900000\n",
      "iteration 239 - count 11950000\n",
      "iteration 240 - count 12000000\n",
      "iteration 241 - count 12050000\n",
      "iteration 242 - count 12100000\n",
      "iteration 243 - count 12150000\n",
      "iteration 244 - count 12200000\n",
      "iteration 245 - count 12250000\n",
      "iteration 246 - count 12300000\n",
      "iteration 247 - count 12350000\n",
      "iteration 248 - count 12400000\n",
      "iteration 249 - count 12450000\n",
      "iteration 250 - count 12500000\n",
      "iteration 251 - count 12550000\n",
      "iteration 252 - count 12600000\n",
      "iteration 253 - count 12650000\n",
      "iteration 254 - count 12700000\n",
      "iteration 255 - count 12750000\n",
      "iteration 256 - count 12800000\n",
      "iteration 257 - count 12850000\n",
      "iteration 258 - count 12900000\n",
      "iteration 259 - count 12950000\n",
      "iteration 260 - count 13000000\n",
      "iteration 261 - count 13050000\n",
      "iteration 262 - count 13100000\n",
      "iteration 263 - count 13150000\n",
      "iteration 264 - count 13200000\n",
      "iteration 265 - count 13250000\n",
      "iteration 266 - count 13300000\n",
      "iteration 267 - count 13350000\n",
      "iteration 268 - count 13400000\n",
      "iteration 269 - count 13450000\n",
      "iteration 270 - count 13500000\n",
      "iteration 271 - count 13550000\n",
      "iteration 272 - count 13600000\n",
      "iteration 273 - count 13650000\n",
      "iteration 274 - count 13700000\n",
      "iteration 275 - count 13750000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 276 - count 13800000\n",
      "iteration 277 - count 13850000\n",
      "iteration 278 - count 13900000\n",
      "iteration 279 - count 13950000\n",
      "iteration 280 - count 14000000\n",
      "iteration 281 - count 14050000\n",
      "iteration 282 - count 14100000\n",
      "iteration 283 - count 14150000\n",
      "iteration 284 - count 14200000\n",
      "iteration 285 - count 14250000\n",
      "iteration 286 - count 14300000\n",
      "iteration 287 - count 14350000\n",
      "iteration 288 - count 14400000\n",
      "iteration 289 - count 14450000\n",
      "iteration 290 - count 14500000\n",
      "iteration 291 - count 14550000\n",
      "iteration 292 - count 14600000\n",
      "iteration 293 - count 14650000\n",
      "iteration 294 - count 14700000\n",
      "iteration 295 - count 14750000\n",
      "iteration 296 - count 14800000\n",
      "iteration 297 - count 14850000\n",
      "iteration 298 - count 14900000\n",
      "iteration 299 - count 14950000\n",
      "iteration 300 - count 15000000\n",
      "iteration 301 - count 15050000\n",
      "iteration 302 - count 15100000\n",
      "iteration 303 - count 15150000\n",
      "iteration 304 - count 15200000\n",
      "iteration 305 - count 15250000\n",
      "iteration 306 - count 15300000\n",
      "iteration 307 - count 15350000\n",
      "iteration 308 - count 15400000\n",
      "iteration 309 - count 15450000\n",
      "iteration 310 - count 15500000\n",
      "iteration 311 - count 15550000\n",
      "iteration 312 - count 15600000\n",
      "iteration 313 - count 15650000\n",
      "iteration 314 - count 15700000\n",
      "iteration 315 - count 15750000\n",
      "iteration 316 - count 15800000\n",
      "iteration 317 - count 15850000\n",
      "iteration 318 - count 15900000\n",
      "iteration 319 - count 15950000\n",
      "iteration 320 - count 16000000\n",
      "iteration 321 - count 16050000\n",
      "iteration 322 - count 16100000\n",
      "iteration 323 - count 16150000\n",
      "iteration 324 - count 16200000\n",
      "iteration 325 - count 16250000\n",
      "iteration 326 - count 16300000\n",
      "iteration 327 - count 16350000\n",
      "iteration 328 - count 16400000\n",
      "iteration 329 - count 16450000\n",
      "iteration 330 - count 16500000\n",
      "iteration 331 - count 16550000\n",
      "iteration 332 - count 16600000\n",
      "iteration 333 - count 16650000\n",
      "iteration 334 - count 16700000\n",
      "iteration 335 - count 16750000\n",
      "iteration 336 - count 16800000\n",
      "iteration 337 - count 16850000\n",
      "iteration 338 - count 16900000\n",
      "iteration 339 - count 16950000\n",
      "iteration 340 - count 17000000\n",
      "iteration 341 - count 17050000\n",
      "iteration 342 - count 17100000\n",
      "iteration 343 - count 17150000\n",
      "iteration 344 - count 17200000\n",
      "iteration 345 - count 17250000\n",
      "iteration 346 - count 17300000\n",
      "iteration 347 - count 17350000\n",
      "iteration 348 - count 17400000\n",
      "iteration 349 - count 17450000\n",
      "iteration 350 - count 17500000\n",
      "iteration 351 - count 17550000\n",
      "iteration 352 - count 17600000\n",
      "iteration 353 - count 17650000\n",
      "iteration 354 - count 17700000\n",
      "iteration 355 - count 17750000\n",
      "iteration 356 - count 17800000\n",
      "iteration 357 - count 17850000\n",
      "iteration 358 - count 17900000\n",
      "iteration 359 - count 17950000\n",
      "iteration 360 - count 18000000\n",
      "iteration 361 - count 18050000\n",
      "iteration 362 - count 18100000\n",
      "iteration 363 - count 18150000\n",
      "iteration 364 - count 18200000\n",
      "iteration 365 - count 18250000\n",
      "iteration 366 - count 18300000\n",
      "iteration 367 - count 18350000\n",
      "iteration 368 - count 18400000\n",
      "iteration 369 - count 18450000\n",
      "iteration 370 - count 18500000\n",
      "iteration 371 - count 18550000\n",
      "iteration 372 - count 18600000\n",
      "iteration 373 - count 18650000\n",
      "iteration 374 - count 18700000\n",
      "iteration 375 - count 18750000\n",
      "iteration 376 - count 18800000\n",
      "iteration 377 - count 18850000\n",
      "iteration 378 - count 18900000\n",
      "iteration 379 - count 18950000\n",
      "iteration 380 - count 19000000\n",
      "iteration 381 - count 19050000\n",
      "iteration 382 - count 19100000\n",
      "iteration 383 - count 19150000\n",
      "iteration 384 - count 19200000\n",
      "iteration 385 - count 19250000\n",
      "iteration 386 - count 19300000\n",
      "iteration 387 - count 19350000\n",
      "iteration 388 - count 19400000\n",
      "iteration 389 - count 19450000\n",
      "iteration 390 - count 19500000\n",
      "iteration 391 - count 19550000\n",
      "iteration 392 - count 19600000\n",
      "iteration 393 - count 19650000\n",
      "iteration 394 - count 19700000\n",
      "iteration 395 - count 19750000\n",
      "iteration 396 - count 19800000\n",
      "iteration 397 - count 19850000\n",
      "iteration 398 - count 19900000\n",
      "iteration 399 - count 19950000\n",
      "iteration 400 - count 20000000\n",
      "iteration 401 - count 20050000\n",
      "iteration 402 - count 20100000\n",
      "iteration 403 - count 20150000\n",
      "iteration 404 - count 20200000\n",
      "iteration 405 - count 20250000\n",
      "iteration 406 - count 20300000\n",
      "iteration 407 - count 20350000\n",
      "iteration 408 - count 20400000\n",
      "iteration 409 - count 20450000\n",
      "iteration 410 - count 20500000\n",
      "iteration 411 - count 20550000\n",
      "iteration 412 - count 20600000\n",
      "iteration 413 - count 20650000\n",
      "iteration 414 - count 20700000\n",
      "iteration 415 - count 20750000\n",
      "iteration 416 - count 20800000\n",
      "iteration 417 - count 20850000\n",
      "iteration 418 - count 20900000\n",
      "iteration 419 - count 20950000\n",
      "iteration 420 - count 21000000\n",
      "iteration 421 - count 21050000\n",
      "iteration 422 - count 21100000\n",
      "iteration 423 - count 21150000\n",
      "iteration 424 - count 21200000\n",
      "iteration 425 - count 21250000\n",
      "iteration 426 - count 21300000\n",
      "iteration 427 - count 21350000\n",
      "iteration 428 - count 21400000\n",
      "iteration 429 - count 21450000\n",
      "iteration 430 - count 21500000\n",
      "iteration 431 - count 21550000\n",
      "iteration 432 - count 21600000\n",
      "iteration 433 - count 21650000\n",
      "iteration 434 - count 21700000\n",
      "iteration 435 - count 21750000\n",
      "iteration 436 - count 21800000\n",
      "iteration 437 - count 21850000\n",
      "iteration 438 - count 21900000\n",
      "iteration 439 - count 21950000\n",
      "iteration 440 - count 22000000\n",
      "iteration 441 - count 22050000\n",
      "iteration 442 - count 22100000\n",
      "iteration 443 - count 22150000\n",
      "iteration 444 - count 22200000\n",
      "iteration 445 - count 22250000\n",
      "iteration 446 - count 22300000\n",
      "iteration 447 - count 22350000\n",
      "iteration 448 - count 22400000\n",
      "iteration 449 - count 22450000\n",
      "iteration 450 - count 22500000\n",
      "iteration 451 - count 22550000\n",
      "iteration 452 - count 22600000\n",
      "iteration 453 - count 22650000\n",
      "iteration 454 - count 22700000\n",
      "iteration 455 - count 22750000\n",
      "iteration 456 - count 22800000\n",
      "iteration 457 - count 22850000\n",
      "iteration 458 - count 22900000\n",
      "iteration 459 - count 22950000\n",
      "iteration 460 - count 23000000\n",
      "iteration 461 - count 23050000\n",
      "iteration 462 - count 23100000\n",
      "iteration 463 - count 23150000\n",
      "iteration 464 - count 23200000\n",
      "iteration 465 - count 23250000\n",
      "iteration 466 - count 23300000\n",
      "iteration 467 - count 23350000\n",
      "iteration 468 - count 23400000\n",
      "iteration 469 - count 23450000\n",
      "iteration 470 - count 23500000\n",
      "iteration 471 - count 23550000\n",
      "iteration 472 - count 23600000\n",
      "iteration 473 - count 23650000\n",
      "iteration 474 - count 23700000\n",
      "iteration 475 - count 23750000\n",
      "iteration 476 - count 23800000\n",
      "iteration 477 - count 23850000\n",
      "iteration 478 - count 23900000\n",
      "iteration 479 - count 23950000\n",
      "iteration 480 - count 24000000\n",
      "iteration 481 - count 24050000\n",
      "iteration 482 - count 24100000\n",
      "iteration 483 - count 24150000\n",
      "iteration 484 - count 24200000\n",
      "iteration 485 - count 24250000\n",
      "iteration 486 - count 24300000\n",
      "iteration 487 - count 24350000\n",
      "iteration 488 - count 24400000\n",
      "iteration 489 - count 24450000\n",
      "iteration 490 - count 24500000\n",
      "iteration 491 - count 24550000\n",
      "iteration 492 - count 24600000\n",
      "iteration 493 - count 24650000\n",
      "iteration 494 - count 24700000\n",
      "iteration 495 - count 24750000\n",
      "iteration 496 - count 24800000\n",
      "iteration 497 - count 24850000\n",
      "iteration 498 - count 24900000\n",
      "iteration 499 - count 24950000\n",
      "iteration 500 - count 25000000\n",
      "iteration 501 - count 25050000\n",
      "iteration 502 - count 25100000\n",
      "iteration 503 - count 25150000\n",
      "iteration 504 - count 25200000\n",
      "iteration 505 - count 25250000\n",
      "iteration 506 - count 25300000\n",
      "iteration 507 - count 25350000\n",
      "iteration 508 - count 25400000\n",
      "iteration 509 - count 25450000\n",
      "iteration 510 - count 25500000\n",
      "iteration 511 - count 25550000\n",
      "iteration 512 - count 25600000\n",
      "iteration 513 - count 25650000\n",
      "iteration 514 - count 25700000\n",
      "iteration 515 - count 25750000\n",
      "iteration 516 - count 25800000\n",
      "iteration 517 - count 25850000\n",
      "iteration 518 - count 25900000\n",
      "iteration 519 - count 25950000\n",
      "iteration 520 - count 26000000\n",
      "iteration 521 - count 26050000\n",
      "iteration 522 - count 26100000\n",
      "iteration 523 - count 26150000\n",
      "iteration 524 - count 26200000\n",
      "iteration 525 - count 26250000\n",
      "iteration 526 - count 26300000\n",
      "iteration 527 - count 26350000\n",
      "iteration 528 - count 26400000\n",
      "iteration 529 - count 26450000\n",
      "iteration 530 - count 26500000\n",
      "iteration 531 - count 26550000\n",
      "iteration 532 - count 26600000\n",
      "iteration 533 - count 26650000\n",
      "iteration 534 - count 26700000\n",
      "iteration 535 - count 26750000\n",
      "iteration 536 - count 26800000\n",
      "iteration 537 - count 26850000\n",
      "iteration 538 - count 26900000\n",
      "iteration 539 - count 26950000\n",
      "iteration 540 - count 27000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 541 - count 27050000\n",
      "iteration 542 - count 27100000\n",
      "iteration 543 - count 27150000\n",
      "iteration 544 - count 27200000\n",
      "iteration 545 - count 27250000\n",
      "iteration 546 - count 27300000\n",
      "iteration 547 - count 27350000\n",
      "iteration 548 - count 27400000\n",
      "iteration 549 - count 27450000\n",
      "iteration 550 - count 27500000\n",
      "iteration 551 - count 27550000\n",
      "iteration 552 - count 27600000\n",
      "iteration 553 - count 27650000\n",
      "iteration 554 - count 27700000\n",
      "iteration 555 - count 27750000\n",
      "iteration 556 - count 27800000\n",
      "iteration 557 - count 27850000\n",
      "iteration 558 - count 27900000\n",
      "iteration 559 - count 27950000\n",
      "iteration 560 - count 28000000\n",
      "iteration 561 - count 28050000\n",
      "iteration 562 - count 28100000\n",
      "iteration 563 - count 28150000\n",
      "iteration 564 - count 28200000\n",
      "iteration 565 - count 28250000\n",
      "iteration 566 - count 28300000\n",
      "iteration 567 - count 28350000\n",
      "iteration 568 - count 28400000\n",
      "iteration 569 - count 28450000\n",
      "iteration 570 - count 28500000\n",
      "iteration 571 - count 28550000\n",
      "iteration 572 - count 28600000\n",
      "iteration 573 - count 28650000\n",
      "iteration 574 - count 28700000\n",
      "iteration 575 - count 28750000\n",
      "iteration 576 - count 28800000\n",
      "iteration 577 - count 28850000\n",
      "iteration 578 - count 28900000\n",
      "iteration 579 - count 28950000\n",
      "iteration 580 - count 29000000\n",
      "iteration 581 - count 29050000\n",
      "iteration 582 - count 29100000\n",
      "iteration 583 - count 29150000\n",
      "iteration 584 - count 29200000\n",
      "iteration 585 - count 29250000\n",
      "iteration 586 - count 29300000\n",
      "iteration 587 - count 29350000\n",
      "iteration 588 - count 29400000\n",
      "iteration 589 - count 29450000\n",
      "iteration 590 - count 29500000\n",
      "iteration 591 - count 29550000\n",
      "iteration 592 - count 29600000\n",
      "iteration 593 - count 29650000\n",
      "iteration 594 - count 29700000\n",
      "iteration 595 - count 29750000\n",
      "iteration 596 - count 29800000\n",
      "iteration 597 - count 29850000\n",
      "iteration 598 - count 29900000\n",
      "iteration 599 - count 29950000\n",
      "iteration 600 - count 30000000\n",
      "iteration 601 - count 30050000\n",
      "iteration 602 - count 30100000\n",
      "iteration 603 - count 30150000\n",
      "iteration 604 - count 30200000\n",
      "iteration 605 - count 30250000\n",
      "iteration 606 - count 30300000\n",
      "iteration 607 - count 30350000\n",
      "iteration 608 - count 30400000\n",
      "iteration 609 - count 30450000\n",
      "iteration 610 - count 30500000\n",
      "iteration 611 - count 30550000\n",
      "iteration 612 - count 30600000\n",
      "iteration 613 - count 30650000\n",
      "iteration 614 - count 30700000\n",
      "iteration 615 - count 30750000\n",
      "iteration 616 - count 30800000\n",
      "iteration 617 - count 30850000\n",
      "iteration 618 - count 30900000\n",
      "iteration 619 - count 30950000\n",
      "iteration 620 - count 31000000\n",
      "iteration 621 - count 31050000\n",
      "iteration 622 - count 31100000\n",
      "iteration 623 - count 31150000\n",
      "iteration 624 - count 31200000\n",
      "iteration 625 - count 31250000\n",
      "iteration 626 - count 31300000\n",
      "iteration 627 - count 31350000\n",
      "iteration 628 - count 31400000\n",
      "iteration 629 - count 31450000\n",
      "iteration 630 - count 31500000\n",
      "iteration 631 - count 31550000\n",
      "iteration 632 - count 31600000\n",
      "iteration 633 - count 31650000\n",
      "iteration 634 - count 31700000\n",
      "iteration 635 - count 31750000\n",
      "iteration 636 - count 31800000\n",
      "iteration 637 - count 31850000\n",
      "iteration 638 - count 31900000\n",
      "iteration 639 - count 31950000\n",
      "iteration 640 - count 32000000\n",
      "iteration 641 - count 32050000\n",
      "iteration 642 - count 32100000\n",
      "iteration 643 - count 32150000\n",
      "iteration 644 - count 32200000\n",
      "iteration 645 - count 32250000\n",
      "iteration 646 - count 32300000\n",
      "iteration 647 - count 32350000\n",
      "iteration 648 - count 32400000\n",
      "iteration 649 - count 32450000\n",
      "iteration 650 - count 32500000\n",
      "iteration 651 - count 32550000\n",
      "iteration 652 - count 32600000\n",
      "iteration 653 - count 32650000\n",
      "iteration 654 - count 32700000\n",
      "iteration 655 - count 32750000\n",
      "iteration 656 - count 32800000\n",
      "iteration 657 - count 32850000\n",
      "iteration 658 - count 32900000\n",
      "iteration 659 - count 32950000\n",
      "iteration 660 - count 33000000\n",
      "iteration 661 - count 33050000\n",
      "iteration 662 - count 33100000\n",
      "iteration 663 - count 33150000\n",
      "iteration 664 - count 33200000\n",
      "iteration 665 - count 33250000\n",
      "iteration 666 - count 33300000\n",
      "iteration 667 - count 33350000\n",
      "iteration 668 - count 33400000\n",
      "iteration 669 - count 33450000\n",
      "iteration 670 - count 33500000\n",
      "iteration 671 - count 33550000\n",
      "iteration 672 - count 33600000\n",
      "iteration 673 - count 33650000\n",
      "iteration 674 - count 33700000\n",
      "iteration 675 - count 33750000\n",
      "iteration 676 - count 33800000\n",
      "iteration 677 - count 33850000\n",
      "iteration 678 - count 33900000\n",
      "iteration 679 - count 33950000\n",
      "iteration 680 - count 34000000\n",
      "iteration 681 - count 34050000\n",
      "iteration 682 - count 34100000\n",
      "iteration 683 - count 34150000\n",
      "iteration 684 - count 34200000\n",
      "iteration 685 - count 34250000\n",
      "iteration 686 - count 34300000\n",
      "iteration 687 - count 34350000\n",
      "iteration 688 - count 34400000\n",
      "iteration 689 - count 34450000\n",
      "iteration 690 - count 34500000\n",
      "iteration 691 - count 34550000\n",
      "iteration 692 - count 34600000\n",
      "iteration 693 - count 34650000\n",
      "iteration 694 - count 34700000\n",
      "iteration 695 - count 34750000\n",
      "iteration 696 - count 34800000\n",
      "iteration 697 - count 34850000\n",
      "iteration 698 - count 34900000\n",
      "iteration 699 - count 34950000\n",
      "iteration 700 - count 35000000\n",
      "iteration 701 - count 35050000\n",
      "iteration 702 - count 35100000\n",
      "iteration 703 - count 35150000\n",
      "iteration 704 - count 35200000\n",
      "iteration 705 - count 35250000\n",
      "iteration 706 - count 35300000\n",
      "iteration 707 - count 35350000\n",
      "iteration 708 - count 35400000\n",
      "iteration 709 - count 35450000\n",
      "iteration 710 - count 35500000\n",
      "iteration 711 - count 35550000\n",
      "iteration 712 - count 35600000\n",
      "iteration 713 - count 35650000\n",
      "iteration 714 - count 35700000\n",
      "iteration 715 - count 35750000\n",
      "iteration 716 - count 35800000\n",
      "iteration 717 - count 35850000\n",
      "iteration 718 - count 35900000\n",
      "iteration 719 - count 35950000\n",
      "iteration 720 - count 36000000\n",
      "iteration 721 - count 36050000\n",
      "iteration 722 - count 36100000\n",
      "iteration 723 - count 36150000\n",
      "iteration 724 - count 36200000\n",
      "iteration 725 - count 36250000\n",
      "iteration 726 - count 36300000\n",
      "iteration 727 - count 36350000\n",
      "iteration 728 - count 36400000\n",
      "iteration 729 - count 36450000\n",
      "iteration 730 - count 36500000\n",
      "iteration 731 - count 36550000\n",
      "iteration 732 - count 36600000\n",
      "iteration 733 - count 36650000\n",
      "iteration 734 - count 36700000\n",
      "iteration 735 - count 36750000\n",
      "iteration 736 - count 36800000\n",
      "iteration 737 - count 36850000\n",
      "iteration 738 - count 36900000\n",
      "iteration 739 - count 36950000\n",
      "iteration 740 - count 37000000\n",
      "iteration 741 - count 37050000\n",
      "iteration 742 - count 37100000\n",
      "iteration 743 - count 37150000\n",
      "iteration 744 - count 37200000\n",
      "iteration 745 - count 37250000\n",
      "iteration 746 - count 37300000\n",
      "iteration 747 - count 37350000\n",
      "iteration 748 - count 37400000\n",
      "iteration 749 - count 37450000\n",
      "iteration 750 - count 37500000\n",
      "iteration 751 - count 37550000\n",
      "iteration 752 - count 37600000\n",
      "iteration 753 - count 37650000\n",
      "iteration 754 - count 37700000\n",
      "iteration 755 - count 37750000\n",
      "iteration 756 - count 37800000\n",
      "iteration 757 - count 37850000\n",
      "iteration 758 - count 37900000\n",
      "iteration 759 - count 37950000\n",
      "iteration 760 - count 38000000\n",
      "iteration 761 - count 38050000\n",
      "iteration 762 - count 38100000\n",
      "iteration 763 - count 38150000\n",
      "iteration 764 - count 38200000\n",
      "iteration 765 - count 38250000\n",
      "iteration 766 - count 38300000\n",
      "iteration 767 - count 38350000\n",
      "iteration 768 - count 38400000\n",
      "iteration 769 - count 38450000\n",
      "iteration 770 - count 38500000\n",
      "iteration 771 - count 38550000\n",
      "iteration 772 - count 38600000\n",
      "iteration 773 - count 38650000\n",
      "iteration 774 - count 38700000\n",
      "iteration 775 - count 38750000\n",
      "iteration 776 - count 38800000\n",
      "iteration 777 - count 38850000\n",
      "iteration 778 - count 38900000\n",
      "iteration 779 - count 38950000\n",
      "iteration 780 - count 39000000\n",
      "iteration 781 - count 39050000\n",
      "iteration 782 - count 39100000\n",
      "iteration 783 - count 39150000\n",
      "iteration 784 - count 39200000\n",
      "iteration 785 - count 39250000\n",
      "iteration 786 - count 39300000\n",
      "iteration 787 - count 39350000\n",
      "iteration 788 - count 39400000\n",
      "iteration 789 - count 39450000\n",
      "iteration 790 - count 39500000\n",
      "iteration 791 - count 39550000\n",
      "iteration 792 - count 39600000\n",
      "iteration 793 - count 39650000\n",
      "iteration 794 - count 39700000\n",
      "iteration 795 - count 39750000\n",
      "iteration 796 - count 39800000\n",
      "iteration 797 - count 39850000\n",
      "iteration 798 - count 39900000\n",
      "iteration 799 - count 39950000\n",
      "iteration 800 - count 40000000\n",
      "iteration 801 - count 40050000\n",
      "iteration 802 - count 40100000\n",
      "iteration 803 - count 40150000\n",
      "iteration 804 - count 40200000\n",
      "iteration 805 - count 40250000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 806 - count 40300000\n",
      "iteration 807 - count 40350000\n",
      "iteration 808 - count 40400000\n",
      "iteration 809 - count 40450000\n",
      "iteration 810 - count 40500000\n",
      "iteration 811 - count 40550000\n",
      "iteration 812 - count 40600000\n",
      "iteration 813 - count 40650000\n",
      "iteration 814 - count 40700000\n",
      "iteration 815 - count 40750000\n",
      "iteration 816 - count 40800000\n",
      "iteration 817 - count 40850000\n",
      "iteration 818 - count 40900000\n",
      "iteration 819 - count 40950000\n",
      "iteration 820 - count 41000000\n",
      "iteration 821 - count 41050000\n",
      "iteration 822 - count 41100000\n",
      "iteration 823 - count 41150000\n",
      "iteration 824 - count 41200000\n",
      "iteration 825 - count 41250000\n",
      "iteration 826 - count 41300000\n",
      "iteration 827 - count 41350000\n",
      "iteration 828 - count 41400000\n",
      "iteration 829 - count 41450000\n",
      "iteration 830 - count 41500000\n",
      "iteration 831 - count 41550000\n",
      "iteration 832 - count 41600000\n",
      "iteration 833 - count 41650000\n"
     ]
    }
   ],
   "source": [
    "#from tqdm import tqdm\n",
    "i=0\n",
    "res = np.zeros((test.shape[0]),dtype=np.float32)\n",
    "step_size = 50000\n",
    "for j in range(int(np.ceil(test.shape[0]/step_size))):\n",
    "    print('iteration {} - count {}'.format(j,i))\n",
    "    for_prediction = get_keras_data(test.iloc[i:i+step_size], numericals, categoricals)\n",
    "    res[i:min(i+step_size,test.shape[0])] = \\\n",
    "       np.expm1(sum([model.predict(for_prediction, batch_size=1024)[:,0] for model in models])/folds)\n",
    "    i+=step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T00:50:04.715156Z",
     "start_time": "2020-04-24T00:47:22.022565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>222.013596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>99.363014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10.074864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>345.728882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1608.276001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>18.422188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>103.637123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>444.614777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>249.868179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>416.182800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>72.985054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>12.715426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1531.255371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>462.440094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>221.189606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>274.239044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>51.317715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>374.259949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>426.199249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>223.191772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>344.078491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1260.057129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>101.347084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>2106.609863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>193.427917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>451.898621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>57.115993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>25.044500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>857.980225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>745.927246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697570</th>\n",
       "      <td>41697570</td>\n",
       "      <td>1883.883301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697571</th>\n",
       "      <td>41697571</td>\n",
       "      <td>45.803780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697572</th>\n",
       "      <td>41697572</td>\n",
       "      <td>32.484035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697573</th>\n",
       "      <td>41697573</td>\n",
       "      <td>401.889374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697574</th>\n",
       "      <td>41697574</td>\n",
       "      <td>161.649490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697575</th>\n",
       "      <td>41697575</td>\n",
       "      <td>130.161957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697576</th>\n",
       "      <td>41697576</td>\n",
       "      <td>192.236633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697577</th>\n",
       "      <td>41697577</td>\n",
       "      <td>467.204315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697578</th>\n",
       "      <td>41697578</td>\n",
       "      <td>46.885445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697579</th>\n",
       "      <td>41697579</td>\n",
       "      <td>403.905029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697580</th>\n",
       "      <td>41697580</td>\n",
       "      <td>71.647690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697581</th>\n",
       "      <td>41697581</td>\n",
       "      <td>172.841919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697582</th>\n",
       "      <td>41697582</td>\n",
       "      <td>7.162432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697583</th>\n",
       "      <td>41697583</td>\n",
       "      <td>19.311430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697584</th>\n",
       "      <td>41697584</td>\n",
       "      <td>870.100403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697585</th>\n",
       "      <td>41697585</td>\n",
       "      <td>428.765228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697586</th>\n",
       "      <td>41697586</td>\n",
       "      <td>605.871521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697587</th>\n",
       "      <td>41697587</td>\n",
       "      <td>126.762123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697588</th>\n",
       "      <td>41697588</td>\n",
       "      <td>381.893829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697589</th>\n",
       "      <td>41697589</td>\n",
       "      <td>186.121857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697590</th>\n",
       "      <td>41697590</td>\n",
       "      <td>260.214020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697591</th>\n",
       "      <td>41697591</td>\n",
       "      <td>294.786285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697592</th>\n",
       "      <td>41697592</td>\n",
       "      <td>94.606308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697593</th>\n",
       "      <td>41697593</td>\n",
       "      <td>2.457937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697594</th>\n",
       "      <td>41697594</td>\n",
       "      <td>92.969177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697595</th>\n",
       "      <td>41697595</td>\n",
       "      <td>6.879961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697596</th>\n",
       "      <td>41697596</td>\n",
       "      <td>4.779332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697597</th>\n",
       "      <td>41697597</td>\n",
       "      <td>2.686898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697598</th>\n",
       "      <td>41697598</td>\n",
       "      <td>190.453659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697599</th>\n",
       "      <td>41697599</td>\n",
       "      <td>3.626055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41697600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  meter_reading\n",
       "0                0     222.013596\n",
       "1                1      99.363014\n",
       "2                2      10.074864\n",
       "3                3     345.728882\n",
       "4                4    1608.276001\n",
       "5                5      18.422188\n",
       "6                6     103.637123\n",
       "7                7     444.614777\n",
       "8                8     249.868179\n",
       "9                9     416.182800\n",
       "10              10      72.985054\n",
       "11              11      12.715426\n",
       "12              12    1531.255371\n",
       "13              13     462.440094\n",
       "14              14     221.189606\n",
       "15              15     274.239044\n",
       "16              16      51.317715\n",
       "17              17     374.259949\n",
       "18              18     426.199249\n",
       "19              19     223.191772\n",
       "20              20     344.078491\n",
       "21              21    1260.057129\n",
       "22              22     101.347084\n",
       "23              23    2106.609863\n",
       "24              24     193.427917\n",
       "25              25     451.898621\n",
       "26              26      57.115993\n",
       "27              27      25.044500\n",
       "28              28     857.980225\n",
       "29              29     745.927246\n",
       "...            ...            ...\n",
       "41697570  41697570    1883.883301\n",
       "41697571  41697571      45.803780\n",
       "41697572  41697572      32.484035\n",
       "41697573  41697573     401.889374\n",
       "41697574  41697574     161.649490\n",
       "41697575  41697575     130.161957\n",
       "41697576  41697576     192.236633\n",
       "41697577  41697577     467.204315\n",
       "41697578  41697578      46.885445\n",
       "41697579  41697579     403.905029\n",
       "41697580  41697580      71.647690\n",
       "41697581  41697581     172.841919\n",
       "41697582  41697582       7.162432\n",
       "41697583  41697583      19.311430\n",
       "41697584  41697584     870.100403\n",
       "41697585  41697585     428.765228\n",
       "41697586  41697586     605.871521\n",
       "41697587  41697587     126.762123\n",
       "41697588  41697588     381.893829\n",
       "41697589  41697589     186.121857\n",
       "41697590  41697590     260.214020\n",
       "41697591  41697591     294.786285\n",
       "41697592  41697592      94.606308\n",
       "41697593  41697593       2.457937\n",
       "41697594  41697594      92.969177\n",
       "41697595  41697595       6.879961\n",
       "41697596  41697596       4.779332\n",
       "41697597  41697597       2.686898\n",
       "41697598  41697598     190.453659\n",
       "41697599  41697599       3.626055\n",
       "\n",
       "[41697600 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['meter_reading'] = res\n",
    "submission.loc[submission['meter_reading']<0, 'meter_reading'] = 0\n",
    "submission.to_csv('submission_nn001.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T21:24:57.636584Z",
     "start_time": "2020-04-23T18:11:39.129Z"
    }
   },
   "outputs": [],
   "source": [
    "#!kaggle competitions submit -c ashrae-energy-prediction -f submission_nn001.csv -m \"Dense NN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T21:24:57.637721Z",
     "start_time": "2020-04-23T18:11:39.130Z"
    }
   },
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
