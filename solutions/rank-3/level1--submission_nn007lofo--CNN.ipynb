{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on GM @aerdem4 Keras CNN (lofoCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(this is a keras tensorflow so no need to change /.keras/keras.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T00:58:03.577032Z",
     "start_time": "2020-04-24T00:58:03.570014Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./weather_test.csv\n",
      "./requirement.txt\n",
      "./level1--submission_multimeter004_nobuild--lightgbm.ipynb\n",
      "./ashrae-energy-prediction.zip\n",
      "./generate_leak_data.ipynb\n",
      "./level1--submission_withoutleak001--lightgbm.ipynb\n",
      "./submission_nn001.csv\n",
      "./train_simple_cleanup.feather\n",
      "./train.csv\n",
      "./level1--submission_nn001--DenseNN - Copy.ipynb\n",
      "./train_cleanup_001.feather\n",
      "./README.md\n",
      "./model_summary.pdf\n",
      "./cpumemuse_densenn.txt\n",
      "./cpumemuse_cnn.txt\n",
      "./weather_train.csv\n",
      "./level1--submission_whatsyourcv3_0052_trncl--lightgbm.ipynb\n",
      "./level1--submission_multimeter003--lightgbm.ipynb\n",
      "./cpumemuse.sh\n",
      "./model_1.hdf5\n",
      "./generate_datasets.ipynb\n",
      "./level1--submission_nn001--DenseNN.ipynb\n",
      "./test.csv\n",
      "./model_0.hdf5\n",
      "./level1--submission_nn007lofo--CNN.ipynb\n",
      "./level2--ensembling_model.ipynb\n",
      "./building_metadata.csv\n",
      "./memuse_log.sh\n",
      "./sample_submission.csv\n",
      "./.ipynb_checkpoints/level1--submission_nn001--DenseNN - Copy-checkpoint.ipynb\n",
      "./.ipynb_checkpoints/level1--submission_nn001--DenseNN-checkpoint.ipynb\n",
      "./.ipynb_checkpoints/level1--submission_nn007lofo--CNN-checkpoint.ipynb\n",
      "./Catboost on GPU/requirement.txt\n",
      "./Catboost on GPU/level1--catboost002--Catboost.ipynb\n",
      "./Keras_NN_weights/cnn_model_0.hdf5\n",
      "./Keras_NN_weights/cnn_model_1.hdf5\n",
      "./Keras_NN_weights/model_1.hdf5\n",
      "./Keras_NN_weights/model_0.hdf5\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('./'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dropout, Dense, Embedding, SpatialDropout1D, concatenate, BatchNormalization, Flatten\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.losses import mean_squared_error as mse_loss\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T00:58:04.478616Z",
     "start_time": "2020-04-24T00:58:03.578901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['building_id', 'meter', 'timestamp', 'site_id', 'primary_use',\n",
       "       'square_feet', 'year_built', 'floor_count', 'na_year_built',\n",
       "       'na_floor_count', 'build_na_total', 'meter_reading_0',\n",
       "       'meter_reading_1', 'meter_reading_2', 'meter_reading_3',\n",
       "       'cnt_building_per_site', 'cnt_building_per_site_prim',\n",
       "       'sqr_mean_per_site', 'sqr_mean_per_prim_site', 'air_temperature',\n",
       "       'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr',\n",
       "       'sea_level_pressure', 'wind_direction', 'wind_speed', 'RH', 'heat',\n",
       "       'windchill', 'feellike', 'air_temperature_mean_lag3',\n",
       "       'dew_temperature_mean_lag3', 'heat_mean_lag3', 'windchill_mean_lag3',\n",
       "       'feellike_mean_lag3', 'had_air_temperature', 'had_cloud_coverage',\n",
       "       'had_dew_temperature', 'had_precip_depth_1_hr',\n",
       "       'had_sea_level_pressure', 'had_wind_direction', 'had_wind_speed',\n",
       "       'had_RH', 'had_heat', 'had_windchill', 'had_feellike',\n",
       "       'had_air_temperature_mean_lag3', 'had_dew_temperature_mean_lag3',\n",
       "       'had_heat_mean_lag3', 'had_windchill_mean_lag3',\n",
       "       'had_feellike_mean_lag3', 'tm_day_of_week', 'tm_hour_of_day',\n",
       "       'meter_reading'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_feather(\"./train_simple_cleanup.feather\")\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T00:58:04.485921Z",
     "start_time": "2020-04-24T00:58:04.480465Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# train[\"primary_use\"] = le.fit_transform(train[\"primary_use\"])\n",
    "\n",
    "categoricals = [\"site_id\", \"building_id\", \"primary_use\", \"tm_hour_of_day\", \"tm_day_of_week\",  \"meter\"]\n",
    "\n",
    "drop_cols = [\"sea_level_pressure\", \"wind_speed\", \"wind_direction\"]\n",
    "\n",
    "fonct_cols_list = ['meter_reading_0',\n",
    "       'meter_reading_1', 'meter_reading_2', 'meter_reading_3',\n",
    "       'cnt_building_per_site', 'cnt_building_per_site_prim',\n",
    "       'sqr_mean_per_site', 'sqr_mean_per_prim_site',\n",
    "       'RH', 'heat',\n",
    "       'windchill', 'feellike', 'air_temperature_mean_lag3',\n",
    "       'dew_temperature_mean_lag3', 'heat_mean_lag3', 'windchill_mean_lag3',]\n",
    "\n",
    "numcols_3d = [\"tm_hour_of_day\", 'RH', 'heat', 'windchill', 'feellike',\n",
    "             \"air_temperature\", \"cloud_coverage\",\"dew_temperature\", \"precip_depth_1_hr\"]\n",
    "\n",
    "had_cols_list = ['had_air_temperature', 'had_cloud_coverage',\n",
    "       'had_dew_temperature', 'had_precip_depth_1_hr',\n",
    "       'had_sea_level_pressure', 'had_wind_direction', 'had_wind_speed',\n",
    "       'had_RH', 'had_heat', 'had_windchill', 'had_feellike',\n",
    "       'had_air_temperature_mean_lag3', 'had_dew_temperature_mean_lag3',\n",
    "       'had_heat_mean_lag3', 'had_windchill_mean_lag3',\n",
    "       'had_feellike_mean_lag3']\n",
    "\n",
    "numericals = [\"square_feet\", \"year_built\", \"air_temperature\", \"cloud_coverage\",\n",
    "              \"dew_temperature\", \"precip_depth_1_hr\", \"floor_count\", ]+drop_cols\n",
    "\n",
    "feat_cols = categoricals + numericals + fonct_cols_list + had_cols_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T00:58:04.492687Z",
     "start_time": "2020-04-24T00:58:04.487772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numcols_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T00:58:14.226163Z",
     "start_time": "2020-04-24T00:58:04.494326Z"
    }
   },
   "outputs": [],
   "source": [
    "train['square_feet'] = train['square_feet'].apply(lambda x: int(x/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T00:58:14.367871Z",
     "start_time": "2020-04-24T00:58:14.227977Z"
    }
   },
   "outputs": [],
   "source": [
    "target = train[\"meter_reading\"]#np.log1p(train[\"meter_reading\"])\n",
    "\n",
    "del train[\"meter_reading\"] \n",
    "\n",
    "# train = train.drop(drop_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T00:58:21.530748Z",
     "start_time": "2020-04-24T00:58:14.369789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'square_feet': 875,\n",
       " 'year_built': 2017,\n",
       " 'air_temperature': 47.2,\n",
       " 'cloud_coverage': 9.0,\n",
       " 'dew_temperature': 35.0,\n",
       " 'precip_depth_1_hr': 343.0,\n",
       " 'floor_count': 26,\n",
       " 'sea_level_pressure': 1045.5,\n",
       " 'wind_speed': 19.0,\n",
       " 'wind_direction': 360.0,\n",
       " 'meter_reading_0': 1,\n",
       " 'meter_reading_1': 1,\n",
       " 'meter_reading_2': 1,\n",
       " 'meter_reading_3': 1,\n",
       " 'cnt_building_per_site': 274,\n",
       " 'cnt_building_per_site_prim': 92,\n",
       " 'sqr_mean_per_site': 290625.0,\n",
       " 'sqr_mean_per_prim_site': 405083.0,\n",
       " 'RH': 158.5,\n",
       " 'heat': 225.71317,\n",
       " 'windchill': 1844.1283,\n",
       " 'feellike': 225.71317,\n",
       " 'air_temperature_mean_lag3': 47.2,\n",
       " 'dew_temperature_mean_lag3': 34.766666,\n",
       " 'heat_mean_lag3': 217.25638,\n",
       " 'windchill_mean_lag3': 1837.2135}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_col = {}\n",
    "for col in numericals+ fonct_cols_list:\n",
    "    if col != 'meter_reading':\n",
    "        max_ = max(-train[col].min(), train[col].max())\n",
    "        train[col] = train[col] / max_\n",
    "        max_col[col]=max_\n",
    "max_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T00:58:21.536562Z",
     "start_time": "2020-04-24T00:58:21.532361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['building_id', 'meter', 'timestamp', 'site_id', 'primary_use',\n",
       "       'square_feet', 'year_built', 'floor_count', 'na_year_built',\n",
       "       'na_floor_count', 'build_na_total', 'meter_reading_0',\n",
       "       'meter_reading_1', 'meter_reading_2', 'meter_reading_3',\n",
       "       'cnt_building_per_site', 'cnt_building_per_site_prim',\n",
       "       'sqr_mean_per_site', 'sqr_mean_per_prim_site', 'air_temperature',\n",
       "       'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr',\n",
       "       'sea_level_pressure', 'wind_direction', 'wind_speed', 'RH', 'heat',\n",
       "       'windchill', 'feellike', 'air_temperature_mean_lag3',\n",
       "       'dew_temperature_mean_lag3', 'heat_mean_lag3', 'windchill_mean_lag3',\n",
       "       'feellike_mean_lag3', 'had_air_temperature', 'had_cloud_coverage',\n",
       "       'had_dew_temperature', 'had_precip_depth_1_hr',\n",
       "       'had_sea_level_pressure', 'had_wind_direction', 'had_wind_speed',\n",
       "       'had_RH', 'had_heat', 'had_windchill', 'had_feellike',\n",
       "       'had_air_temperature_mean_lag3', 'had_dew_temperature_mean_lag3',\n",
       "       'had_heat_mean_lag3', 'had_windchill_mean_lag3',\n",
       "       'had_feellike_mean_lag3', 'tm_day_of_week', 'tm_hour_of_day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T00:58:21.558632Z",
     "start_time": "2020-04-24T00:58:21.538320Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/divrikwicky/lightweight-version-of-2-65-custom-nn\n",
    "\n",
    "def nn_block(input_layer, size, dropout_rate, activation):\n",
    "    out_layer = Dense(size, activation=None)(input_layer)\n",
    "    out_layer = BatchNormalization()(out_layer)\n",
    "    out_layer = Activation(activation)(out_layer)\n",
    "    out_layer = Dropout(dropout_rate)(out_layer)\n",
    "    return out_layer\n",
    "\n",
    "def cnn_block(input_layer, size, dropout_rate, activation):\n",
    "    out_layer = Conv1D(size, 1, activation=None)(input_layer)\n",
    "    out_layer = BatchNormalization()(out_layer)\n",
    "    out_layer = Activation(activation)(out_layer)\n",
    "    out_layer = Dropout(dropout_rate)(out_layer)\n",
    "    return out_layer\n",
    "\n",
    "def model_lofo(dense_dim_1=64, dense_dim_2=32, dense_dim_3=32, dense_dim_4=16, \n",
    "            dropout1=0.2, dropout2=0.1, dropout3=0.1, dropout4=0.1, lr=0.001):\n",
    "\n",
    "    #Inputs\n",
    "    site_id = Input(shape=[1], name=\"site_id\")\n",
    "    building_id = Input(shape=[1], name=\"building_id\")\n",
    "    meter = Input(shape=[1], name=\"meter\")\n",
    "    primary_use = Input(shape=[1], name=\"primary_use\")\n",
    "    square_feet = Input(shape=[1], name=\"square_feet\")\n",
    "    year_built = Input(shape=[1], name=\"year_built\")\n",
    "    air_temperature = Input(shape=[1], name=\"air_temperature\")\n",
    "    cloud_coverage = Input(shape=[1], name=\"cloud_coverage\")\n",
    "    dew_temperature = Input(shape=[1], name=\"dew_temperature\")\n",
    "    tm_hour_of_day = Input(shape=[1], name=\"tm_hour_of_day\")\n",
    "    precip = Input(shape=[1], name=\"precip_depth_1_hr\")\n",
    "    tm_day_of_week = Input(shape=[1], name=\"tm_day_of_week\")\n",
    "#     beaufort_scale = Input(shape=[1], name=\"beaufort_scale\")\n",
    "\n",
    "    orig_feature = Input(shape=[len(numericals)], name=\"orig_feature\")\n",
    "    had_cols = Input(shape=[len(had_cols_list)], name=\"had_cols\")\n",
    "    fonct_cols = Input(shape=[len(fonct_cols_list)], name=\"fonct_cols\")\n",
    "    \n",
    "    all_num3D = Input(shape=(train[numcols_3d].shape[1], 3), name=\"all_num3D\")\n",
    "   \n",
    "    #Embeddings layers\n",
    "    emb_site_id = Embedding(16, 2)(site_id)\n",
    "    emb_building_id = Embedding(1449, 3)(building_id)\n",
    "    emb_meter = Embedding(4, 2)(meter)\n",
    "    emb_primary_use = Embedding(16, 2)(primary_use)\n",
    "#     emb_hour = Embedding(24, 2)(tm_hour_of_day)\n",
    "#     emb_weekday = Embedding(7, 2)(tm_day_of_week)\n",
    "\n",
    "    concat_emb = concatenate([\n",
    "           Flatten() (emb_site_id)\n",
    "         , Flatten() (emb_building_id)\n",
    "         , Flatten() (emb_primary_use)\n",
    "#          , Flatten() (emb_hour)\n",
    "#          , Flatten() (emb_weekday)\n",
    "    ])\n",
    "    \n",
    "#     categ = Dropout(dropout1)(Dense(dense_dim_1,activation='relu') (concat_emb))\n",
    "#     categ = BatchNormalization()(categ)\n",
    "#     categ = Dropout(dropout2)(Dense(dense_dim_2,activation='relu') (categ))\n",
    "    \n",
    "    #main layer\n",
    "    main_l = concatenate([\n",
    "#           categ\n",
    "        square_feet\n",
    "        , year_built\n",
    "        , air_temperature\n",
    "        , cloud_coverage\n",
    "        , dew_temperature\n",
    "        , tm_hour_of_day\n",
    "        , tm_day_of_week\n",
    "        , precip\n",
    "#         , beaufort_scale\n",
    "    ])\n",
    "    dense_input = concatenate([orig_feature, concat_emb, had_cols, fonct_cols])\n",
    "\n",
    "#     type_input = Input(shape=(1,))\n",
    "#     type_emb = Flatten()(Embedding(dev_df[\"le_type\"].max() + 1, 5)(type_input))\n",
    "\n",
    "    type_emb = Flatten()(emb_meter)\n",
    "    \n",
    "    mol_input = all_num3D #RepeatVector(3)(dense_input) #Input(shape=(M_train.shape[1], M_train.shape[2]))\n",
    "    mol_layer = cnn_block(mol_input, 200, 0.05, \"relu\")\n",
    "    mol_layer = cnn_block(mol_layer, 100, 0.05, \"relu\")\n",
    "    \n",
    "    merged_input = BatchNormalization()(concatenate([dense_input, type_emb, \n",
    "                                                     GlobalMaxPooling1D()(mol_layer), GlobalAvgPool1D()(mol_layer)]))\n",
    "    \n",
    "    x1 = Dense(200, activation=\"relu\")(merged_input)\n",
    "    x2 = nn_block(x1, 20, 0.01, \"sigmoid\")\n",
    "    \n",
    "    mol_layer = concatenate([RepeatVector(9)(x2), mol_layer])\n",
    "    mol_layer = cnn_block(mol_layer, 200, 0.05, \"relu\")\n",
    "    mol_layer = cnn_block(mol_layer, 100, 0.05, \"relu\")\n",
    "    merged_input = BatchNormalization()(concatenate([dense_input, type_emb, \n",
    "                                                     GlobalMaxPooling1D()(mol_layer), GlobalAvgPool1D()(mol_layer)]))\n",
    "    hidden_layer = concatenate([Dense(600, activation=\"relu\")(merged_input), x1])\n",
    "    \n",
    "    hidden_layer = nn_block(hidden_layer, 400, 0.05, \"relu\")\n",
    "    hidden_layer = nn_block(hidden_layer, 200, 0.05, \"relu\")\n",
    "    hidden_layer = nn_block(hidden_layer, 100, 0.05, \"relu\")\n",
    "    \n",
    "    hidden_layer = concatenate([Flatten()(emb_meter), hidden_layer])\n",
    "    \n",
    "    output = Dense(1, activation=\"linear\")(hidden_layer)\n",
    "\n",
    "\n",
    "    model = Model([ site_id,\n",
    "                    building_id, \n",
    "                    meter, \n",
    "                    primary_use, \n",
    "                    square_feet, \n",
    "                    year_built, \n",
    "                   \n",
    "                    air_temperature,\n",
    "                    cloud_coverage,\n",
    "                    dew_temperature, \n",
    "                    tm_hour_of_day,\n",
    "                    tm_day_of_week, \n",
    "                   precip,\n",
    "                   \n",
    "                   all_num3D,\n",
    "                   orig_feature,\n",
    "                   had_cols,\n",
    "                   fonct_cols,\n",
    "                    \n",
    "                    ], output)\n",
    "\n",
    "    model.compile(optimizer = Nadam(lr=lr),\n",
    "                  loss= mse_loss,\n",
    "                  metrics=[root_mean_squared_error])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T00:58:21.563665Z",
     "start_time": "2020-04-24T00:58:21.560480Z"
    }
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T00:58:21.574071Z",
     "start_time": "2020-04-24T00:58:21.565396Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\"\n",
    "    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T00:58:47.521831Z",
     "start_time": "2020-04-24T00:58:21.575828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 3144.50 MB\n",
      "Memory usage after optimization is: 2486.35 MB\n",
      "Decreased by 20.9%\n",
      "Memory usage of dataframe is 731.28 MB\n",
      "Memory usage after optimization is: 658.15 MB\n",
      "Decreased by 10.0%\n",
      "Memory usage of dataframe is 731.28 MB\n",
      "Memory usage after optimization is: 658.15 MB\n",
      "Decreased by 10.0%\n"
     ]
    }
   ],
   "source": [
    "# introduction of lagged features (-1 hours and -2 hours)\n",
    "\n",
    "train = reduce_mem_usage(train)\n",
    "\n",
    "train1 = train.groupby(['building_id', 'meter'])[numcols_3d].shift(1).fillna(0)\n",
    "train1 = reduce_mem_usage(train1)\n",
    "train2 = train.groupby(['building_id', 'meter'])[numcols_3d].shift(2).fillna(0)\n",
    "train2 = reduce_mem_usage(train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T00:58:47.531950Z",
     "start_time": "2020-04-24T00:58:47.523836Z"
    }
   },
   "outputs": [],
   "source": [
    "# fct to return the data as 3D table embeded into a dictionnary:\n",
    "def get_keras_data(df, df1, df2, num_cols, cat_cols):\n",
    "    cols = cat_cols + num_cols\n",
    "    X = {col: np.array(df[col]) for col in cols}\n",
    "    X['orig_feature'] = np.array(df[numericals])\n",
    "    X['had_cols'] = np.array(df[had_cols_list])\n",
    "    X['fonct_cols'] = np.array(df[fonct_cols_list])\n",
    "    \n",
    "    X['all_num0'] = np.array(df[numcols_3d])\n",
    "    X['all_num1'] = np.array(df1[numcols_3d])\n",
    "    X['all_num2'] = np.array(df2[numcols_3d])\n",
    "    \n",
    "    M = np.zeros((df[numcols_3d].shape[0], df[numcols_3d].shape[1], 3), dtype=np.float32)\n",
    "    M[:,:,0] = X['all_num0']\n",
    "    M[:,:,1] = X['all_num1']\n",
    "    M[:,:,2] = X['all_num2']\n",
    "    \n",
    "    X['all_num3D'] = M\n",
    "    \n",
    "    return X\n",
    "\n",
    "def train_model(keras_model, X_t, y_train, batch_size, epochs, X_v, y_valid, fold, patience=3):\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=1)\n",
    "    model_checkpoint = ModelCheckpoint(\"cnn_model_\" + str(fold) + \".hdf5\",\n",
    "                                       save_best_only=True, verbose=1, monitor='val_root_mean_squared_error', mode='min')\n",
    "\n",
    "    hist = keras_model.fit(X_t, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                            validation_data=(X_v, y_valid), verbose=1,\n",
    "                            callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "    keras_model = load_model(\"cnn_model_\" + str(fold) + \".hdf5\", custom_objects={'root_mean_squared_error': root_mean_squared_error})\n",
    "    \n",
    "    return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T11:02:16.663542Z",
     "start_time": "2020-04-24T00:58:47.533777Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 9585011 samples, validate on 9585012 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:184: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "9585011/9585011 [==============================] - 3630s 379us/step - loss: 0.8325 - root_mean_squared_error: 0.8641 - val_loss: 0.8401 - val_root_mean_squared_error: 0.9065\n",
      "\n",
      "Epoch 00001: val_root_mean_squared_error improved from inf to 0.90654, saving model to cnn_model_0.hdf5\n",
      "Epoch 2/5\n",
      "9585011/9585011 [==============================] - 3576s 373us/step - loss: 0.5040 - root_mean_squared_error: 0.7094 - val_loss: 0.7353 - val_root_mean_squared_error: 0.8522\n",
      "\n",
      "Epoch 00002: val_root_mean_squared_error improved from 0.90654 to 0.85224, saving model to cnn_model_0.hdf5\n",
      "Epoch 3/5\n",
      "9585011/9585011 [==============================] - 3573s 373us/step - loss: 0.4579 - root_mean_squared_error: 0.6762 - val_loss: 0.6950 - val_root_mean_squared_error: 0.8292\n",
      "\n",
      "Epoch 00003: val_root_mean_squared_error improved from 0.85224 to 0.82922, saving model to cnn_model_0.hdf5\n",
      "Epoch 4/5\n",
      "9585011/9585011 [==============================] - 3576s 373us/step - loss: 0.4321 - root_mean_squared_error: 0.6568 - val_loss: 0.6792 - val_root_mean_squared_error: 0.8194\n",
      "\n",
      "Epoch 00004: val_root_mean_squared_error improved from 0.82922 to 0.81943, saving model to cnn_model_0.hdf5\n",
      "Epoch 5/5\n",
      "9585011/9585011 [==============================] - 3577s 373us/step - loss: 0.4136 - root_mean_squared_error: 0.6426 - val_loss: 0.6774 - val_root_mean_squared_error: 0.8182\n",
      "\n",
      "Epoch 00005: val_root_mean_squared_error improved from 0.81943 to 0.81823, saving model to cnn_model_0.hdf5\n",
      "**************************************************\n",
      "Fold: 1\n",
      "Train on 9585012 samples, validate on 9585011 samples\n",
      "Epoch 1/5\n",
      "9585012/9585012 [==============================] - 3638s 380us/step - loss: 0.8299 - root_mean_squared_error: 0.8532 - val_loss: 0.7704 - val_root_mean_squared_error: 0.8728\n",
      "\n",
      "Epoch 00001: val_root_mean_squared_error improved from inf to 0.87276, saving model to cnn_model_1.hdf5\n",
      "Epoch 2/5\n",
      "9585012/9585012 [==============================] - 3646s 380us/step - loss: 0.4813 - root_mean_squared_error: 0.6932 - val_loss: 0.7119 - val_root_mean_squared_error: 0.8386\n",
      "\n",
      "Epoch 00002: val_root_mean_squared_error improved from 0.87276 to 0.83858, saving model to cnn_model_1.hdf5\n",
      "Epoch 3/5\n",
      "9585012/9585012 [==============================] - 3635s 379us/step - loss: 0.4366 - root_mean_squared_error: 0.6603 - val_loss: 0.7054 - val_root_mean_squared_error: 0.8352\n",
      "\n",
      "Epoch 00003: val_root_mean_squared_error improved from 0.83858 to 0.83516, saving model to cnn_model_1.hdf5\n",
      "Epoch 4/5\n",
      "9585012/9585012 [==============================] - 3637s 379us/step - loss: 0.4123 - root_mean_squared_error: 0.6416 - val_loss: 0.6885 - val_root_mean_squared_error: 0.8247\n",
      "\n",
      "Epoch 00004: val_root_mean_squared_error improved from 0.83516 to 0.82474, saving model to cnn_model_1.hdf5\n",
      "Epoch 5/5\n",
      "9585012/9585012 [==============================] - 3663s 382us/step - loss: 0.3958 - root_mean_squared_error: 0.6286 - val_loss: 0.6918 - val_root_mean_squared_error: 0.8252\n",
      "\n",
      "Epoch 00005: val_root_mean_squared_error did not improve from 0.82474\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "import gc\n",
    "# from sklearn.model_selection import GroupKFold\n",
    "# \n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "oof = np.zeros(len(train))\n",
    "batch_size = 4096\n",
    "epochs = 5\n",
    "models = []\n",
    "\n",
    "\n",
    "seed = 666\n",
    "\n",
    "folds = 2\n",
    "kf = KFold(n_splits=folds, shuffle=False, random_state=seed)\n",
    "\n",
    "for fold_n, (train_index, valid_index) in enumerate(kf.split(train, target)):\n",
    "    \n",
    "# for fold_n, (train_index, valid_index) in enumerate(weirdfolds):\n",
    "    print('Fold:', fold_n)\n",
    "    X_train, X_valid = train.iloc[train_index], train.iloc[valid_index]\n",
    "    y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "    \n",
    "    X_train1, X_valid1 = train1.iloc[train_index], train1.iloc[valid_index]\n",
    "    X_train2, X_valid2 = train2.iloc[train_index], train2.iloc[valid_index]\n",
    " \n",
    "    \n",
    "    \n",
    "#     X_train, X_valid = train.iloc[valid_index], train.iloc[train_index]\n",
    "#     y_train, y_valid = target.iloc[valid_index], target.iloc[train_index]\n",
    "    \n",
    "    X_t = get_keras_data(X_train, X_train1, X_train2,  numericals, categoricals)\n",
    "    X_v = get_keras_data(X_valid, X_valid1, X_valid2, numericals, categoricals)\n",
    "    del X_train, X_valid, X_train1, X_valid1,X_train2, X_valid2\n",
    "    gc.collect()\n",
    "    \n",
    "    keras_model = model_lofo(dense_dim_1=64, dense_dim_2=64, dense_dim_3=16, dense_dim_4=8, \n",
    "                        dropout1=0.2, dropout2=0.1, dropout3=0.1, dropout4=0.1, lr=0.001)\n",
    "    mod = train_model(keras_model, X_t, y_train, batch_size, epochs, X_v, y_valid, fold_n, patience=3)\n",
    "    models.append(mod)\n",
    "    gc.collect()\n",
    "    print('*'* 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T11:02:16.838234Z",
     "start_time": "2020-04-24T11:02:16.666364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T11:02:16.845181Z",
     "start_time": "2020-04-24T11:02:16.840754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.training.Model at 0x7f638c224da0>,\n",
       " <keras.engine.training.Model at 0x7f61fe2743c8>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T11:02:16.851232Z",
     "start_time": "2020-04-24T11:02:16.847320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['square_feet',\n",
       " 'year_built',\n",
       " 'air_temperature',\n",
       " 'cloud_coverage',\n",
       " 'dew_temperature',\n",
       " 'precip_depth_1_hr',\n",
       " 'floor_count',\n",
       " 'sea_level_pressure',\n",
       " 'wind_speed',\n",
       " 'wind_direction']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T11:02:16.856173Z",
     "start_time": "2020-04-24T11:02:16.853427Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T11:02:18.895835Z",
     "start_time": "2020-04-24T11:02:16.858106Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_feather('test_simple_cleanup.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T11:02:41.033230Z",
     "start_time": "2020-04-24T11:02:18.898323Z"
    }
   },
   "outputs": [],
   "source": [
    "test['square_feet'] = test['square_feet'].apply(lambda x: int(x/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T11:02:43.361756Z",
     "start_time": "2020-04-24T11:02:41.035280Z"
    }
   },
   "outputs": [],
   "source": [
    "test = test[feat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T11:02:43.383783Z",
     "start_time": "2020-04-24T11:02:43.363790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 45)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feat_cols), len(['site_id',\n",
    " 'building_id',\n",
    " 'primary_use',\n",
    " 'tm_hour_of_day',\n",
    " 'tm_day_of_week',\n",
    " 'meter',\n",
    " 'square_feet',\n",
    " 'year_built',\n",
    " 'air_temperature',\n",
    " 'cloud_coverage',\n",
    " 'dew_temperature',\n",
    " 'precip_depth_1_hr',\n",
    " 'floor_count',\n",
    " 'meter_reading_0',\n",
    " 'meter_reading_1',\n",
    " 'meter_reading_2',\n",
    " 'meter_reading_3',\n",
    " 'cnt_building_per_site',\n",
    " 'cnt_building_per_site_prim',\n",
    " 'sqr_mean_per_site',\n",
    " 'sqr_mean_per_prim_site',\n",
    " 'RH',\n",
    " 'heat',\n",
    " 'windchill',\n",
    " 'feellike',\n",
    " 'air_temperature_mean_lag3',\n",
    " 'dew_temperature_mean_lag3',\n",
    " 'heat_mean_lag3',\n",
    " 'windchill_mean_lag3',\n",
    " 'had_air_temperature',\n",
    " 'had_cloud_coverage',\n",
    " 'had_dew_temperature',\n",
    " 'had_precip_depth_1_hr',\n",
    " 'had_sea_level_pressure',\n",
    " 'had_wind_direction',\n",
    " 'had_wind_speed',\n",
    " 'had_RH',\n",
    " 'had_heat',\n",
    " 'had_windchill',\n",
    " 'had_feellike',\n",
    " 'had_air_temperature_mean_lag3',\n",
    " 'had_dew_temperature_mean_lag3',\n",
    " 'had_heat_mean_lag3',\n",
    " 'had_windchill_mean_lag3',\n",
    " 'had_feellike_mean_lag3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T11:02:43.391186Z",
     "start_time": "2020-04-24T11:02:43.385666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['site_id',\n",
       " 'building_id',\n",
       " 'primary_use',\n",
       " 'tm_hour_of_day',\n",
       " 'tm_day_of_week',\n",
       " 'meter',\n",
       " 'square_feet',\n",
       " 'year_built',\n",
       " 'air_temperature',\n",
       " 'cloud_coverage',\n",
       " 'dew_temperature',\n",
       " 'precip_depth_1_hr',\n",
       " 'floor_count',\n",
       " 'sea_level_pressure',\n",
       " 'wind_speed',\n",
       " 'wind_direction',\n",
       " 'meter_reading_0',\n",
       " 'meter_reading_1',\n",
       " 'meter_reading_2',\n",
       " 'meter_reading_3',\n",
       " 'cnt_building_per_site',\n",
       " 'cnt_building_per_site_prim',\n",
       " 'sqr_mean_per_site',\n",
       " 'sqr_mean_per_prim_site',\n",
       " 'RH',\n",
       " 'heat',\n",
       " 'windchill',\n",
       " 'feellike',\n",
       " 'air_temperature_mean_lag3',\n",
       " 'dew_temperature_mean_lag3',\n",
       " 'heat_mean_lag3',\n",
       " 'windchill_mean_lag3',\n",
       " 'had_air_temperature',\n",
       " 'had_cloud_coverage',\n",
       " 'had_dew_temperature',\n",
       " 'had_precip_depth_1_hr',\n",
       " 'had_sea_level_pressure',\n",
       " 'had_wind_direction',\n",
       " 'had_wind_speed',\n",
       " 'had_RH',\n",
       " 'had_heat',\n",
       " 'had_windchill',\n",
       " 'had_feellike',\n",
       " 'had_air_temperature_mean_lag3',\n",
       " 'had_dew_temperature_mean_lag3',\n",
       " 'had_heat_mean_lag3',\n",
       " 'had_windchill_mean_lag3',\n",
       " 'had_feellike_mean_lag3']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T11:02:43.397188Z",
     "start_time": "2020-04-24T11:02:43.393066Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'square_feet': 875,\n",
       " 'year_built': 2017,\n",
       " 'air_temperature': 47.2,\n",
       " 'cloud_coverage': 9.0,\n",
       " 'dew_temperature': 35.0,\n",
       " 'precip_depth_1_hr': 343.0,\n",
       " 'floor_count': 26,\n",
       " 'sea_level_pressure': 1045.5,\n",
       " 'wind_speed': 19.0,\n",
       " 'wind_direction': 360.0,\n",
       " 'meter_reading_0': 1,\n",
       " 'meter_reading_1': 1,\n",
       " 'meter_reading_2': 1,\n",
       " 'meter_reading_3': 1,\n",
       " 'cnt_building_per_site': 274,\n",
       " 'cnt_building_per_site_prim': 92,\n",
       " 'sqr_mean_per_site': 290625.0,\n",
       " 'sqr_mean_per_prim_site': 405083.0,\n",
       " 'RH': 158.5,\n",
       " 'heat': 225.71317,\n",
       " 'windchill': 1844.1283,\n",
       " 'feellike': 225.71317,\n",
       " 'air_temperature_mean_lag3': 47.2,\n",
       " 'dew_temperature_mean_lag3': 34.766666,\n",
       " 'heat_mean_lag3': 217.25638,\n",
       " 'windchill_mean_lag3': 1837.2135}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T11:02:47.829735Z",
     "start_time": "2020-04-24T11:02:43.399225Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for col in numericals+ fonct_cols_list:\n",
    "    if col != 'meter_reading':\n",
    "#         max_ = max(-train[col].min(), train[col].max())\n",
    "        test[col] = test[col] / max_col[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T11:03:38.402357Z",
     "start_time": "2020-04-24T11:02:47.831688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 6481.85 MB\n",
      "Memory usage after optimization is: 5050.27 MB\n",
      "Decreased by 22.1%\n",
      "Memory usage of dataframe is 1590.64 MB\n",
      "Memory usage after optimization is: 1431.57 MB\n",
      "Decreased by 10.0%\n",
      "Memory usage of dataframe is 1590.64 MB\n",
      "Memory usage after optimization is: 1431.57 MB\n",
      "Decreased by 10.0%\n"
     ]
    }
   ],
   "source": [
    "test = reduce_mem_usage(test)\n",
    "\n",
    "test1 = test.groupby(['building_id', 'meter'])[numcols_3d].shift(1).fillna(0)\n",
    "test1 = reduce_mem_usage(test1)\n",
    "test2 = test.groupby(['building_id', 'meter'])[numcols_3d].shift(2).fillna(0)\n",
    "test2 = reduce_mem_usage(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T11:03:38.408515Z",
     "start_time": "2020-04-24T11:03:38.404496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numcols_3d), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T13:31:31.842605Z",
     "start_time": "2020-04-24T11:03:38.410633Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 834/834 [2:27:53<00:00, 10.44s/it]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "i=0\n",
    "\n",
    "res = np.zeros((test.shape[0]),dtype=np.float32)\n",
    "step_size = 50000\n",
    "for j in tqdm(range(int(np.ceil(test.shape[0]/step_size)))):\n",
    "#     for_prediction = get_keras_data(test.iloc[i:i+step_size], numericals, categoricals)\n",
    "    for_prediction = get_keras_data(test.iloc[i:i+step_size], test1.iloc[i:i+step_size], test2.iloc[i:i+step_size], numericals, categoricals)\n",
    "    res[i:min(i+step_size,test.shape[0])] = \\\n",
    "       np.expm1(sum([model.predict(for_prediction, batch_size=1024)[:,0] for model in models])/len(models))\n",
    "    i+=step_size\n",
    "\n",
    "# for_prediction = get_keras_data(test, test1, test2, numericals, categoricals)\n",
    "# res = np.expm1(sum([model.predict(for_prediction, batch_size=1024)[:,0] for model in models])/len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T13:31:31.851496Z",
     "start_time": "2020-04-24T13:31:31.845753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([203.54323  ,  95.53644  ,   6.8410177, ...,   5.516595 ,\n",
       "       178.66592  ,   3.6301134], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T13:31:38.723100Z",
     "start_time": "2020-04-24T13:31:31.854228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>203.543228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>95.536438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6.841018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>340.223480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1176.802124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>10.261471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>106.060509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>467.563904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1583.618896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>367.068634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>91.413116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>94.716377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1276.405029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>426.043030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>202.110901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>276.566223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>577.799255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>343.352631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1101.685303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>219.064972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>840.463562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1020.036072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>99.704575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1512.368896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>188.638397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>395.385803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>44.878643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>13.689162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>700.719055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>714.273010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697570</th>\n",
       "      <td>41697570</td>\n",
       "      <td>1517.793701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697571</th>\n",
       "      <td>41697571</td>\n",
       "      <td>40.982704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697572</th>\n",
       "      <td>41697572</td>\n",
       "      <td>27.709978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697573</th>\n",
       "      <td>41697573</td>\n",
       "      <td>440.349701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697574</th>\n",
       "      <td>41697574</td>\n",
       "      <td>154.664459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697575</th>\n",
       "      <td>41697575</td>\n",
       "      <td>120.819656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697576</th>\n",
       "      <td>41697576</td>\n",
       "      <td>169.300446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697577</th>\n",
       "      <td>41697577</td>\n",
       "      <td>484.967133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697578</th>\n",
       "      <td>41697578</td>\n",
       "      <td>31.778187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697579</th>\n",
       "      <td>41697579</td>\n",
       "      <td>545.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697580</th>\n",
       "      <td>41697580</td>\n",
       "      <td>78.213379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697581</th>\n",
       "      <td>41697581</td>\n",
       "      <td>191.629089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697582</th>\n",
       "      <td>41697582</td>\n",
       "      <td>5.921728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697583</th>\n",
       "      <td>41697583</td>\n",
       "      <td>10.995721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697584</th>\n",
       "      <td>41697584</td>\n",
       "      <td>535.730042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697585</th>\n",
       "      <td>41697585</td>\n",
       "      <td>366.996155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697586</th>\n",
       "      <td>41697586</td>\n",
       "      <td>467.892456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697587</th>\n",
       "      <td>41697587</td>\n",
       "      <td>150.006226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697588</th>\n",
       "      <td>41697588</td>\n",
       "      <td>376.116547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697589</th>\n",
       "      <td>41697589</td>\n",
       "      <td>191.708740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697590</th>\n",
       "      <td>41697590</td>\n",
       "      <td>287.840057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697591</th>\n",
       "      <td>41697591</td>\n",
       "      <td>291.595764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697592</th>\n",
       "      <td>41697592</td>\n",
       "      <td>86.843964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697593</th>\n",
       "      <td>41697593</td>\n",
       "      <td>1.634948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697594</th>\n",
       "      <td>41697594</td>\n",
       "      <td>83.969002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697595</th>\n",
       "      <td>41697595</td>\n",
       "      <td>6.973897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697596</th>\n",
       "      <td>41697596</td>\n",
       "      <td>4.004656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697597</th>\n",
       "      <td>41697597</td>\n",
       "      <td>5.516595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697598</th>\n",
       "      <td>41697598</td>\n",
       "      <td>178.665924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697599</th>\n",
       "      <td>41697599</td>\n",
       "      <td>3.630113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41697600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  meter_reading\n",
       "0                0     203.543228\n",
       "1                1      95.536438\n",
       "2                2       6.841018\n",
       "3                3     340.223480\n",
       "4                4    1176.802124\n",
       "5                5      10.261471\n",
       "6                6     106.060509\n",
       "7                7     467.563904\n",
       "8                8    1583.618896\n",
       "9                9     367.068634\n",
       "10              10      91.413116\n",
       "11              11      94.716377\n",
       "12              12    1276.405029\n",
       "13              13     426.043030\n",
       "14              14     202.110901\n",
       "15              15     276.566223\n",
       "16              16     577.799255\n",
       "17              17     343.352631\n",
       "18              18    1101.685303\n",
       "19              19     219.064972\n",
       "20              20     840.463562\n",
       "21              21    1020.036072\n",
       "22              22      99.704575\n",
       "23              23    1512.368896\n",
       "24              24     188.638397\n",
       "25              25     395.385803\n",
       "26              26      44.878643\n",
       "27              27      13.689162\n",
       "28              28     700.719055\n",
       "29              29     714.273010\n",
       "...            ...            ...\n",
       "41697570  41697570    1517.793701\n",
       "41697571  41697571      40.982704\n",
       "41697572  41697572      27.709978\n",
       "41697573  41697573     440.349701\n",
       "41697574  41697574     154.664459\n",
       "41697575  41697575     120.819656\n",
       "41697576  41697576     169.300446\n",
       "41697577  41697577     484.967133\n",
       "41697578  41697578      31.778187\n",
       "41697579  41697579     545.027100\n",
       "41697580  41697580      78.213379\n",
       "41697581  41697581     191.629089\n",
       "41697582  41697582       5.921728\n",
       "41697583  41697583      10.995721\n",
       "41697584  41697584     535.730042\n",
       "41697585  41697585     366.996155\n",
       "41697586  41697586     467.892456\n",
       "41697587  41697587     150.006226\n",
       "41697588  41697588     376.116547\n",
       "41697589  41697589     191.708740\n",
       "41697590  41697590     287.840057\n",
       "41697591  41697591     291.595764\n",
       "41697592  41697592      86.843964\n",
       "41697593  41697593       1.634948\n",
       "41697594  41697594      83.969002\n",
       "41697595  41697595       6.973897\n",
       "41697596  41697596       4.004656\n",
       "41697597  41697597       5.516595\n",
       "41697598  41697598     178.665924\n",
       "41697599  41697599       3.630113\n",
       "\n",
       "[41697600 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['meter_reading'] = res\n",
    "submission.loc[submission['meter_reading']<0, 'meter_reading'] = 0\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T13:36:31.769875Z",
     "start_time": "2020-04-24T13:31:38.725243Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission_nn007lofo.csv.gz', index=False, compression='gzip', float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T13:36:31.775485Z",
     "start_time": "2020-04-24T13:36:31.772599Z"
    }
   },
   "outputs": [],
   "source": [
    "#!kaggle competitions submit -c ashrae-energy-prediction -f submission_nn007lofo.csv.gz -m \"keras cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T13:36:31.781703Z",
     "start_time": "2020-04-24T13:36:31.777366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
