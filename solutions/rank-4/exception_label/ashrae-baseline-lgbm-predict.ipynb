{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, gc, sys, warnings, random, math, psutil, pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Helpers\n",
    "#################################################################################\n",
    "## Seeder\n",
    "# :seed to make all processes deterministic     # type: int\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "## Simple \"Memory profilers\" to see memory usage\n",
    "def get_memory_usage():\n",
    "    return np.round(psutil.Process(os.getpid()).memory_info()[0]/2.**30, 2) \n",
    "        \n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Vars\n",
    "#################################################################################\n",
    "SEED = 42\n",
    "LOCAl_TEST = False\n",
    "seed_everything(SEED)\n",
    "TARGET = 'meter_reading'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n"
     ]
    }
   ],
   "source": [
    "########################### DATA LOAD\n",
    "#################################################################################\n",
    "print('Load Data')\n",
    "# train_df = pd.read_pickle('../input/ashrae-data-minification/train.pkl')\n",
    "test_df = pd.read_pickle('../output/ashrae-data-minification/test.pkl')\n",
    "\n",
    "building_df = pd.read_pickle('../output/ashrae-data-minification/building_metadata.pkl')\n",
    "\n",
    "# train_weather_df = pd.read_pickle('../input/ashrae-data-minification/weather_train.pkl')\n",
    "test_weather_df = pd.read_pickle('../output/ashrae-data-minification/weather_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Building DF merge through concat \n",
    "#################################################################################\n",
    "# Benefits of concat:\n",
    "## Faster for huge datasets (columns number)\n",
    "## No dtype change for dataset\n",
    "## Consume less memmory \n",
    "\n",
    "# temp_df = train_df[['building_id']]\n",
    "# temp_df = temp_df.merge(building_df, on=['building_id'], how='left')\n",
    "# del temp_df['building_id']\n",
    "# train_df = pd.concat([train_df, temp_df], axis=1)\n",
    "\n",
    "temp_df = test_df[['building_id']]\n",
    "temp_df = temp_df.merge(building_df, on=['building_id'], how='left')\n",
    "del temp_df['building_id']\n",
    "test_df = pd.concat([test_df, temp_df], axis=1)\n",
    "\n",
    "del building_df, temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Weather DF merge over concat (to not lose type)\n",
    "#################################################################################\n",
    "# Benefits of concat:\n",
    "## Faster for huge datasets (columns number)\n",
    "## No dtype change for dataset\n",
    "## Consume less memmory \n",
    "\n",
    "# temp_df = train_df[['site_id','timestamp']]\n",
    "# temp_df = temp_df.merge(train_weather_df, on=['site_id','timestamp'], how='left')\n",
    "# del temp_df['site_id'], temp_df['timestamp']\n",
    "# train_df = pd.concat([train_df, temp_df], axis=1)\n",
    "\n",
    "temp_df = test_df[['site_id','timestamp']]\n",
    "temp_df = temp_df.merge(test_weather_df, on=['site_id','timestamp'], how='left')\n",
    "del temp_df['site_id'], temp_df['timestamp']\n",
    "test_df = pd.concat([test_df, temp_df], axis=1)\n",
    "\n",
    "del test_weather_df, temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################### Trick to use kernel hdd to store results\n",
    "#################################################################################\n",
    "\n",
    "# You can save just test_df or both if have sufficient space\n",
    "# train_df.to_pickle('train_df.pkl')\n",
    "test_df.to_pickle('../output/ashrae-baseline-lgbm-predict/test_df.pkl')\n",
    "   \n",
    "del test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           _ii:   807.0B\n",
      "                          _i10:   807.0B\n",
      "                          _i19:   807.0B\n",
      "                           _i2:   715.0B\n",
      "                           _i6:   715.0B\n",
      "                          _i15:   715.0B\n",
      "                          _iii:   712.0B\n",
      "                           _i9:   712.0B\n",
      "                          _i18:   712.0B\n",
      "                           _i8:   604.0B\n",
      "Memory in Gb 0.09\n"
     ]
    }
   ],
   "source": [
    "########################### Check memory usage\n",
    "#################################################################################\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name,value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name,sizeof_fmt(size)))\n",
    "print('Memory in Gb', get_memory_usage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for seed 42\n",
      "Predicting batch: 0\n",
      "Predicting batch: 1\n",
      "Predicting batch: 2\n",
      "Predicting batch: 3\n",
      "Predicting batch: 4\n",
      "Predicting batch: 5\n",
      "Predicting batch: 6\n",
      "Predicting batch: 7\n",
      "Predicting batch: 8\n",
      "Predicting batch: 9\n",
      "Predicting batch: 10\n",
      "Predicting batch: 11\n",
      "Predicting batch: 12\n",
      "Predicting batch: 13\n",
      "Predicting batch: 14\n",
      "Predicting batch: 15\n",
      "Predicting batch: 16\n",
      "Predicting batch: 17\n",
      "Predicting batch: 18\n",
      "Predicting batch: 19\n",
      "Predicting batch: 20\n",
      "Predictions for seed 43\n",
      "Predicting batch: 0\n",
      "Predicting batch: 1\n",
      "Predicting batch: 2\n",
      "Predicting batch: 3\n",
      "Predicting batch: 4\n",
      "Predicting batch: 5\n",
      "Predicting batch: 6\n",
      "Predicting batch: 7\n",
      "Predicting batch: 8\n",
      "Predicting batch: 9\n",
      "Predicting batch: 10\n",
      "Predicting batch: 11\n",
      "Predicting batch: 12\n",
      "Predicting batch: 13\n",
      "Predicting batch: 14\n",
      "Predicting batch: 15\n",
      "Predicting batch: 16\n",
      "Predicting batch: 17\n",
      "Predicting batch: 18\n",
      "Predicting batch: 19\n",
      "Predicting batch: 20\n",
      "Predictions for seed 44\n",
      "Predicting batch: 0\n",
      "Predicting batch: 1\n",
      "Predicting batch: 2\n",
      "Predicting batch: 3\n",
      "Predicting batch: 4\n",
      "Predicting batch: 5\n",
      "Predicting batch: 6\n",
      "Predicting batch: 7\n",
      "Predicting batch: 8\n",
      "Predicting batch: 9\n",
      "Predicting batch: 10\n",
      "Predicting batch: 11\n",
      "Predicting batch: 12\n",
      "Predicting batch: 13\n",
      "Predicting batch: 14\n",
      "Predicting batch: 15\n",
      "Predicting batch: 16\n",
      "Predicting batch: 17\n",
      "Predicting batch: 18\n",
      "Predicting batch: 19\n",
      "Predicting batch: 20\n",
      "Predictions for seed 45\n",
      "Predicting batch: 0\n",
      "Predicting batch: 1\n",
      "Predicting batch: 2\n",
      "Predicting batch: 3\n",
      "Predicting batch: 4\n",
      "Predicting batch: 5\n",
      "Predicting batch: 6\n",
      "Predicting batch: 7\n",
      "Predicting batch: 8\n",
      "Predicting batch: 9\n",
      "Predicting batch: 10\n",
      "Predicting batch: 11\n",
      "Predicting batch: 12\n",
      "Predicting batch: 13\n",
      "Predicting batch: 14\n",
      "Predicting batch: 15\n",
      "Predicting batch: 16\n",
      "Predicting batch: 17\n",
      "Predicting batch: 18\n",
      "Predicting batch: 19\n",
      "Predicting batch: 20\n",
      "Predictions for seed 46\n",
      "Predicting batch: 0\n",
      "Predicting batch: 1\n",
      "Predicting batch: 2\n",
      "Predicting batch: 3\n",
      "Predicting batch: 4\n",
      "Predicting batch: 5\n",
      "Predicting batch: 6\n",
      "Predicting batch: 7\n",
      "Predicting batch: 8\n",
      "Predicting batch: 9\n",
      "Predicting batch: 10\n",
      "Predicting batch: 11\n",
      "Predicting batch: 12\n",
      "Predicting batch: 13\n",
      "Predicting batch: 14\n",
      "Predicting batch: 15\n",
      "Predicting batch: 16\n",
      "Predicting batch: 17\n",
      "Predicting batch: 18\n",
      "Predicting batch: 19\n",
      "Predicting batch: 20\n",
      "    meter_reading  row_id\n",
      "0       12.600851       0\n",
      "1       12.685303       1\n",
      "2       11.595356       2\n",
      "3       61.798067       3\n",
      "4      115.873078       4\n",
      "5        9.127420       5\n",
      "6       47.320986       6\n",
      "7      137.591172       7\n",
      "8       14.155544       8\n",
      "9       89.538251       9\n",
      "10      63.193183      10\n",
      "11      18.881466      11\n",
      "12     252.920196      12\n",
      "13      42.784190      13\n",
      "14      42.376791      14\n",
      "15      85.542175      15\n",
      "16       4.863037      16\n",
      "17     139.612100      17\n",
      "18      16.765880      18\n",
      "19      94.978122      19\n",
      "count    4.169760e+07\n",
      "mean     3.838341e+02\n",
      "std      1.144660e+04\n",
      "min      0.000000e+00\n",
      "25%      2.182279e+01\n",
      "50%      6.970323e+01\n",
      "75%      1.853188e+02\n",
      "max      2.609283e+06\n",
      "Name: meter_reading, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "########################### Predict\n",
    "#################################################################################\n",
    "if not LOCAl_TEST:\n",
    "    \n",
    "    # Load test_df from hdd\n",
    "    test_df = pd.read_pickle('../output/ashrae-baseline-lgbm-predict/test_df.pkl')\n",
    "\n",
    "    remove_columns = ['timestamp',TARGET,'site_id','row_id']\n",
    "    features_columns = [col for col in list(test_df) if col not in remove_columns]\n",
    "    \n",
    "    # Remove unused columns\n",
    "    test_df = test_df[features_columns]\n",
    "    \n",
    "    # Remove test_df from hdd\n",
    "    os.system('rm test_df.pkl')\n",
    "    \n",
    "    # Read submission file\n",
    "    submission = pd.read_csv('../input/ashrae-energy-prediction/sample_submission.csv')\n",
    "\n",
    "    # Remove row_id for a while\n",
    "    del submission['row_id']\n",
    "    \n",
    "    for i in range(2, 7):\n",
    "        print(f'Predictions for seed 4{i}')\n",
    "        estimator = pickle.load(open(f'../output/test-lgb-model/lgbm__seed_4{i}.bin', 'rb'))\n",
    "\n",
    "        predictions = []\n",
    "        batch_size = 2000000\n",
    "        for batch in range(int(len(test_df)/batch_size)+1):\n",
    "            print('Predicting batch:', batch)\n",
    "            predictions += list(np.expm1(estimator.predict(test_df[features_columns].iloc[batch*batch_size:(batch+1)*batch_size])))\n",
    "            \n",
    "        submission['meter_reading'] += predictions\n",
    "        del estimator\n",
    "        gc.collect()\n",
    "        \n",
    "    # Average over models\n",
    "    submission['meter_reading'] /= 5\n",
    "    \n",
    "    # Delete test_df\n",
    "    del test_df\n",
    "     \n",
    "    # Fix negative values\n",
    "    submission['meter_reading'] = submission['meter_reading'].clip(0,None)\n",
    "\n",
    "    # Restore row_id\n",
    "    submission['row_id'] = submission.index\n",
    "    \n",
    "    ########################### Check\n",
    "    print(submission.iloc[:20])\n",
    "    print(submission['meter_reading'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Export\n",
    "#################################################################################\n",
    "if not LOCAl_TEST:\n",
    "    submission.to_csv('../output/ashrae-baseline-lgbm-predict/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
